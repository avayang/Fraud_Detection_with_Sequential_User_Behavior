{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformer_v7_train_new.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"F9jRvrvOuhyN","colab":{}},"source":["#!pip install -q tf-nightly"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aBqbXLFcTrGx","colab":{}},"source":["import tensorflow as tf\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import json\n","import os \n","import pickle\n","import tensorflow_addons as tfa\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wefq0VtXoAnK","colab_type":"code","outputId":"c293c7e0-3324-44a3-beb3-c57d7c25b8f2","executionInfo":{"status":"ok","timestamp":1590182599874,"user_tz":-480,"elapsed":17282,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# os.chdir(\"drive/My Drive/Code _ Data/6.new_data\") \n","os.chdir(\"drive/My Drive/Online Lending/Sequential Embedding/Spring 2020/Final Submission/Data/high_income_data/processed\") # give the path to the data file.\n","os.listdir()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['features_sequential_embedded.json',\n"," 'label.json',\n"," 'non_sequential_features.json',\n"," 'featurematrix.json',\n"," 'padded_sequential_features.json',\n"," 'embedding_sequence.p',\n"," 'stay_time_sequence.p',\n"," 'checkpoints']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B4Y3wO6HB24T"},"source":["# Setup Input"]},{"cell_type":"code","metadata":{"id":"50d7hjnaFHUH","colab_type":"code","outputId":"b884c6ef-5c22-4667-897e-f3965321eb16","executionInfo":{"status":"ok","timestamp":1590182661388,"user_tz":-480,"elapsed":55842,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":54,"output_embedded_package_id":"1ZIbEhLRPCRpcSQRtQOvi7GlyWC-G36Wd"}},"source":["with open('label.json') as f:\n","    labels = json.load(f)\n","with open('embedding_sequence.p', 'rb') as f:\n","    embedding_sequence = pickle.load(f)\n","with open('stay_time_sequence.p', 'rb') as f:\n","    stay_time_sequence = pickle.load(f)\n","label = np.array([[labels[key]] for key in labels.keys()], dtype=np.float32)\n","embedding_sequence = np.array(embedding_sequence, dtype=np.float32)\n","stay_time_sequence = np.array(stay_time_sequence, dtype=np.float32)\n","stay_time_sequence = stay_time_sequence.reshape(-1, 60, 1)\n","labels.keys()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"3HmYvMjqIxAQ","colab_type":"code","outputId":"6fff23c5-f325-416c-c99e-3ad15f26ae4c","executionInfo":{"status":"ok","timestamp":1590182954098,"user_tz":-480,"elapsed":304,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["stay_time_sequence.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(149923, 60, 1)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"lZJzJQqTG1zT","colab_type":"code","outputId":"86f0a0a1-232c-43f2-a85d-71972653cd31","executionInfo":{"status":"ok","timestamp":1590182954670,"user_tz":-480,"elapsed":158,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embedding_sequence.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(149923, 60, 50)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hnBYQfzZG29T","colab_type":"code","outputId":"d0d3af76-0587-499e-b989-0b331412cad7","executionInfo":{"status":"ok","timestamp":1590182955295,"user_tz":-480,"elapsed":269,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["label.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(149923, 1)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"PoECi-tyIsSW","colab_type":"text"},"source":["# Train Test Split"]},{"cell_type":"code","metadata":{"id":"dSGkI--IIpu5","colab_type":"code","outputId":"79aac869-e7d3-4c06-f540-9917859a9a8c","executionInfo":{"status":"ok","timestamp":1590095474023,"user_tz":-480,"elapsed":87539,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_behavior, test_behavior, train_stay_time, test_stay_time, train_label, test_label = train_test_split(\n","    embedding_sequence, stay_time_sequence, label, test_size=0.1)\n","train_behavior.shape, train_stay_time.shape, train_label.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((134930, 60, 50), (134930, 60, 1), (134930, 1))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"e4F1R6XEB7IK"},"source":["# Set Hyperparameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ecGq_EhKCDzO","colab":{}},"source":["#num_layers = 4\n","#d_model = 128\n","#dff = 512\n","#num_heads = 8\n","\n","#input_size = 149923\n","#target_size = 149923\n","# dropout_rate = 0.1\n","batch_size = 64\n","learning_rate = 0.01"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jqljvnZ6pLsF","colab_type":"text"},"source":["# Positional Encoding"]},{"cell_type":"code","metadata":{"id":"O2zcKFg1pQlK","colab_type":"code","colab":{}},"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","  return pos * angle_rates"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KCHD25npcCK","colab_type":"code","colab":{}},"source":["def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  \n","  # apply sin to even indices in the array; 2i\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  \n","  # apply cos to odd indices in the array; 2i+1\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    \n","  pos_encoding = angle_rads[np.newaxis, ...]\n","    \n","  return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRlOBaHbpeVA","colab_type":"code","outputId":"0302ba78-51fe-420d-ef78-84a92c9e0c15","executionInfo":{"status":"ok","timestamp":1590095474024,"user_tz":-480,"elapsed":87530,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pos_encoding = positional_encoding(50, 512)\n","print (pos_encoding.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1, 50, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sluYz8Y8ChFI"},"source":["# Multi-head Attention Layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"whwDsev94z7P","colab":{}},"source":["#In this architecture, we choose to construct without mask \n","def scaled_dot_product_attention(q, k, v):\n","  \"\"\"\n","  Calculate the attention weights.\n","  q, k, v must have matching leading dimensions.\n","  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","  The mask has different shapes depending on its type(padding or look ahead) \n","  but it must be broadcastable for addition.\n","  \n","  Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","    \n","  Returns:\n","    output, attention_weights\n","  \"\"\"\n","\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","  \n","  # scale matmul_qk\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # add the mask to the scaled tensor.\n","  #if mask is not None:\n","  #  scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores\n","  # add up to 1.\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","  return output, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0WJHF6h07xfJ","colab":{}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x, batch_size):\n","    \"\"\"Split the last dimension into (num_heads, depth).\n","    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","    \"\"\"\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","  def call(self, v, k, q):\n","    batch_size = tf.shape(q)[0]\n","    \n","    q = self.wq(q)  # (batch_size, seq_len, d_model)\n","    k = self.wk(k)  # (batch_size, seq_len, d_model)\n","    v = self.wv(v)  # (batch_size, seq_len, d_model)\n","    \n","    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","    \n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v)\n","    \n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","    return output, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Qv2wKJOXI2g2"},"source":["# Feed-forward Network"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DD0eWLmMVkTg","colab":{}},"source":["def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RNbOBX5bI9Vl"},"source":["# Encoder Layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Km19ly8eVlDO","colab":{}},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training):\n","\n","    attn_output, _ = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(x + ffn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    return out2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YTH8jTBV0HQc","outputId":"9a80f3b6-8fe5-4b30-9468-9619e872ddd3","executionInfo":{"status":"ok","timestamp":1590095474026,"user_tz":-480,"elapsed":87520,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sample_encoder_layer = EncoderLayer(512, 8, 2048)\n","\n","sample_encoder_layer_output = sample_encoder_layer(\n","    tf.random.uniform((64, 60, 512)), False)\n","\n","sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 60, 512])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ew74cBXgJGuf"},"source":["# Decoder Layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r4um4cTowWFK","colab":{}},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","    # self.ffn1 = point_wise_feed_forward_network(d_model, dff)\n","    self.ffn2 = point_wise_feed_forward_network(d_model, dff)\n"," \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","  def call(self, x, enc_output, training):\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","    # ffn_output1 = self.ffn1(x)  # (batch_size, input_seq_len, d_model)\n","    # ffn_output1 = self.dropout1(ffn_output1, training=training)\n","    # out1 = self.layernorm1(x + ffn_output1)  # (batch_size, input_seq_len, d_model)\n","\n","    attn1, attn_weights_block1 = self.mha1(x, x, x)  # (batch_size, target_seq_len, d_model)\n","    attn1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(attn1 + x)\n","    \n","    attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1)  # (batch_size, target_seq_len, d_model)\n","    attn2 = self.dropout2(attn2, training=training)\n","    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","    \n","    ffn_output2 = self.ffn2(out2)  # (batch_size, target_seq_len, d_model)\n","    ffn_output2 = self.dropout3(ffn_output2, training=training)\n","    out3 = self.layernorm3(ffn_output2 + out2)  # (batch_size, target_seq_len, d_model)\n","    \n","    return out3, attn_weights_block2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M-ptSgD-zXbd","outputId":"def513c7-0178-467d-fd51-909d1c49a575","executionInfo":{"status":"ok","timestamp":1590095474027,"user_tz":-480,"elapsed":87515,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sample_decoder_layer = DecoderLayer(512, 8, 2048)\n","\n","sample_decoder_layer_output, _ = sample_decoder_layer(tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, False)\n","\n","sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 50, 512])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uNXpkkD212aA"},"source":["# Encoder"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IL83Fmuxzvs3","colab":{}},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","  def call(self, x, training):\n","\n","    seq_len = tf.shape(x)[1]\n","    \n","    # adding embedding and position encoding.\n","    # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training)\n","    \n","    return x  # (batch_size, input_seq_len, d_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pcwg1aJL2TC3","outputId":"743bd3e3-8174-471b-8ff2-6260590b4417","executionInfo":{"status":"ok","timestamp":1590095474027,"user_tz":-480,"elapsed":87508,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sample_encoder = Encoder(num_layers=2, d_model=50, num_heads=10, dff=2048, maximum_position_encoding=60)\n","temp_input = tf.random.uniform((64, 60, 50), dtype=tf.float32, minval=0, maxval=200)\n","\n","sample_encoder_output = sample_encoder(temp_input, training=False)\n","\n","print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(64, 60, 50)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2GmiOgTI6CoA"},"source":["# Decoder"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ox5uDtH74rf3","colab":{}},"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    #self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","    \n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","    \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, enc_output, training):\n","\n","    seq_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    \n","    #x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","    \n","    x = self.dropout(x, training=training)\n","\n","    for i in range(self.num_layers):\n","      x, block2 = self.dec_layers[i](x, enc_output, training)\n","      \n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","    # x.shape == (batch_size, target_seq_len, d_model)\n","    return x, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CBt9ctWd5KRK","outputId":"8153d053-4b9a-4c39-8f7f-1e66545e9524","executionInfo":{"status":"ok","timestamp":1590095474029,"user_tz":-480,"elapsed":87504,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sample_decoder = Decoder(num_layers=2, d_model=50, num_heads=5, dff=2048, maximum_position_encoding=60)\n","temp_input = tf.random.uniform((64, 26, 50), dtype=tf.float32, minval=0, maxval=200)\n","\n","output, attn = sample_decoder(temp_input,enc_output=sample_encoder_output,training=False)\n","\n","output.shape, attn['decoder_layer2_block2'].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 26, 50]), TensorShape([64, 5, 26, 60]))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0MZ0IUzb7XP-"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sageC2fJ7H8h","colab":{}},"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_size, maximum_position_encoding, rate=0.1):\n","    super(Transformer, self).__init__()\n","\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, maximum_position_encoding, rate)\n","\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, maximum_position_encoding, rate)\n","\n","    self.final_layer1 = tf.keras.layers.Dense(target_size)\n","    self.final_layer3 = tf.keras.layers.Dense(1, activation = \"sigmoid\")\n","    \n","  def call(self, inp, tar, training, batch_size):\n","\n","    enc_output = self.encoder(inp, training)  # (batch_size, inp_seq_len, d_model)\n","    \n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","    dec_output, attention_weights = self.decoder(tar, enc_output, training)\n","    \n","    final_output1 = self.final_layer1(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","    final_output2 = tf.reshape(final_output1, (batch_size, -1))\n","    final_output3 = self.final_layer3(final_output2)\n","    return final_output3, attention_weights\n","sample_transformer = Transformer(num_layers=2, d_model=50, num_heads=10, dff=512, target_size=60, maximum_position_encoding=60)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYjupeadDwqk","colab_type":"code","outputId":"3e2005f5-bc5a-4f2d-965c-57e9230f9dfe","executionInfo":{"status":"ok","timestamp":1590095474030,"user_tz":-480,"elapsed":87499,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.executing_eagerly() "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xFcBZAmV8UCB","outputId":"43c5ed57-62f5-4751-8006-c64385113f74","executionInfo":{"status":"ok","timestamp":1590095474031,"user_tz":-480,"elapsed":87495,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["sample_transformer = Transformer(num_layers=2, d_model=50, num_heads=10, dff=512, target_size=60, maximum_position_encoding=60)\n","\n","#temp_input = tf.random.uniform((100,60,50), dtype=tf.float32, minval=0, maxval=200)\n","#temp_target = tf.random.uniform((100,60,1), dtype=tf.float32, minval=0, maxval=200)\n","fn_out, _ = sample_transformer(embedding_sequence[:32], stay_time_sequence[:32], training=False, batch_size=32)\n","\n","# fn_out, _ = sample_transformer(temp_input, temp_target, training=False)\n","\n","fn_out  # (batch_size, tar_seq_len, target_vocab_size)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n","array([[0.5590977 ],\n","       [0.56253517],\n","       [0.5634813 ],\n","       [0.59959376],\n","       [0.56450486],\n","       [0.5343397 ],\n","       [0.5762417 ],\n","       [0.6645876 ],\n","       [0.54990107],\n","       [0.5670042 ],\n","       [0.5374921 ],\n","       [0.5686124 ],\n","       [0.47458327],\n","       [0.43931648],\n","       [0.5491694 ],\n","       [0.5294906 ],\n","       [0.5370212 ],\n","       [0.51806325],\n","       [0.48748764],\n","       [0.59075475],\n","       [0.589478  ],\n","       [0.5547391 ],\n","       [0.5775752 ],\n","       [0.5576585 ],\n","       [0.5564946 ],\n","       [0.55572504],\n","       [0.5984175 ],\n","       [0.629127  ],\n","       [0.5670979 ],\n","       [0.5594499 ],\n","       [0.5750337 ],\n","       [0.45594856]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"7HsFcn43o9ey","colab_type":"text"},"source":["# Optimizer"]},{"cell_type":"code","metadata":{"id":"8xJM6-PV0_SL","colab_type":"code","colab":{}},"source":["learning_rate = 0.1\n","optimizer = tf.keras.optimizers.Adam(learning_rate, epsilon=1e-9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVUoZKCeeSxh","colab_type":"code","colab":{}},"source":["# d_model=50"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WM5hmcwonwhK","colab_type":"text"},"source":["# loss"]},{"cell_type":"code","metadata":{"id":"liDoYckDMiqR","colab_type":"code","colab":{}},"source":["def loss_function(y_true, y_pred):\n","  # dot_product = y*tf.log(output)\n","  # xentropy = -tf.reduce_sum(dot_product, reduction_indices=1)\n","  # loss = tf.reduce_mean(xentropy)\n","#   bce = tf.keras.losses.BinaryCrossentropy()\n","#   loss = bce(y_true, y_pred)\n","\n","  sfce = tfa.losses.SigmoidFocalCrossEntropy()\n","  loss = sfce(y_true, y_pred)\n","\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoWv_lOJveBq","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"W59fNB4rviMK","colab_type":"code","colab":{}},"source":["# def evaluate(output, y):\n","#     \"\"\"\n","#     evaluates the accuracy on the validation set \n","#     input:\n","#         -output: prediction vector of the network for the validation set\n","#         -y: true value for the validation set\n","#     output:\n","#         - accuracy: accuracy on the validation set (scalar between 0 and 1)\n","#     \"\"\"\n","#     #correct prediction is a binary vector which equals one when the output and y match\n","#     #otherwise the vector equals 0\n","#     #tf.cast: change the type of a tensor into another one2\n","#     #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n","    \n","#     correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n","#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","#     tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n","#     return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_WgTgjqO-6l0","colab_type":"text"},"source":["# Main Function"]},{"cell_type":"code","metadata":{"id":"IQQSoWaJk8Xm","colab_type":"code","colab":{}},"source":["def data_generator(x1, x2, y, batch_size=32):\n","  while True:\n","    total_batch = len(y)//batch_size\n","    # if total_batch < len(y)/batch_size:\n","    #   total_batch += 1\n","    batch_ind = 0\n","    while batch_ind < total_batch:\n","      start = batch_ind * batch_size\n","      end = (batch_ind + 1) * batch_size\n","      batch_ind += 1\n","      yield x1[start:end], x2[start:end], y[start:end]\n","# g = data_generator(x1,x2,y)\n","# next(g)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjdHW8s-Hb13","colab_type":"code","colab":{}},"source":["x1 = train_behavior[:]\n","x2 = train_stay_time[:]\n","y = train_label[:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgRak8Q11kf4","colab_type":"code","colab":{}},"source":["checkpoint_path = \"checkpoints/train\"\n","\n","ckpt = tf.train.Checkpoint(transformer=sample_transformer,optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","# if ckpt_manager.latest_checkpoint:\n","#   ckpt.restore(ckpt_manager.latest_checkpoint)\n","#   print ('Latest checkpoint restored!!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gq7kubToU-yF","colab_type":"code","colab":{}},"source":["# The @tf.function trace-compiles train_step into a TF graph for faster\n","# execution. The function specializes to the precise shape of the argument\n","# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n","# batch sizes (the last batch is smaller), use input_signature to specify\n","# more generic shapes.\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(batch_size, 60, 50), dtype=tf.float32),\n","    tf.TensorSpec(shape=(batch_size, 60, 1), dtype=tf.float32),\n","    tf.TensorSpec(shape=(batch_size, 1), dtype=tf.float32)\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp1, inp2, tar):\n","  \n","  with tf.GradientTape() as tape:\n","    predictions, _ = sample_transformer(inp1, inp2, True, batch_size)\n","    loss = loss_function(tar, predictions)\n","\n","  gradients = tape.gradient(loss, sample_transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, sample_transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar, predictions)\n","  train_AUC(tar, predictions)\n","  # print(predictions[:10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvgYrpD7VC8P","colab_type":"code","outputId":"90c2dfa4-05ba-4084-b5eb-b4c7defb2fdf","executionInfo":{"status":"ok","timestamp":1590101190040,"user_tz":-480,"elapsed":5803486,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["EPOCHS = 8\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n","train_AUC = tf.keras.metrics.AUC(name='train_AUC')\n","# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","optimizer = tf.keras.optimizers.Adam()\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  train_AUC.reset_states()\n","  total_batch = int(len(x1)/batch_size)\n","  # if total_batch < len(y)/batch_size:\n","  #   total_batch += 1\n","  data = data_generator(x1, x2, y, batch_size)\n","  for batch_ind in range(total_batch): \n","    minibatch_x1, minibatch_x2, minibatch_y = next(data)\n","    train_step(minibatch_x1, minibatch_x2, minibatch_y)\n","    if batch_ind % 10 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n","          epoch + 1, batch_ind, train_loss.result(), train_accuracy.result(), train_AUC.result()))\n","      \n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, train_loss.result(),train_accuracy.result()))\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 0.1461 Accuracy 0.5469 AUC 0.4836\n","Epoch 1 Batch 10 Loss 0.0991 Accuracy 0.8636 AUC 0.4989\n","Epoch 1 Batch 20 Loss 0.1155 Accuracy 0.8891 AUC 0.4945\n","Epoch 1 Batch 30 Loss 0.0897 Accuracy 0.9068 AUC 0.4639\n","Epoch 1 Batch 40 Loss 0.0778 Accuracy 0.9108 AUC 0.4756\n","Epoch 1 Batch 50 Loss 0.0681 Accuracy 0.9157 AUC 0.4740\n","Epoch 1 Batch 60 Loss 0.0622 Accuracy 0.9162 AUC 0.4894\n","Epoch 1 Batch 70 Loss 0.0570 Accuracy 0.9186 AUC 0.4946\n","Epoch 1 Batch 80 Loss 0.0537 Accuracy 0.9192 AUC 0.4956\n","Epoch 1 Batch 90 Loss 0.0506 Accuracy 0.9208 AUC 0.4972\n","Epoch 1 Batch 100 Loss 0.0483 Accuracy 0.9220 AUC 0.4979\n","Epoch 1 Batch 110 Loss 0.0465 Accuracy 0.9222 AUC 0.4979\n","Epoch 1 Batch 120 Loss 0.0446 Accuracy 0.9236 AUC 0.4980\n","Epoch 1 Batch 130 Loss 0.0433 Accuracy 0.9241 AUC 0.4979\n","Epoch 1 Batch 140 Loss 0.0421 Accuracy 0.9249 AUC 0.5004\n","Epoch 1 Batch 150 Loss 0.0409 Accuracy 0.9255 AUC 0.5026\n","Epoch 1 Batch 160 Loss 0.0403 Accuracy 0.9254 AUC 0.5017\n","Epoch 1 Batch 170 Loss 0.0398 Accuracy 0.9254 AUC 0.4993\n","Epoch 1 Batch 180 Loss 0.0390 Accuracy 0.9258 AUC 0.5022\n","Epoch 1 Batch 190 Loss 0.0383 Accuracy 0.9263 AUC 0.5004\n","Epoch 1 Batch 200 Loss 0.0378 Accuracy 0.9262 AUC 0.5012\n","Epoch 1 Batch 210 Loss 0.0370 Accuracy 0.9272 AUC 0.5013\n","Epoch 1 Batch 220 Loss 0.0363 Accuracy 0.9278 AUC 0.5033\n","Epoch 1 Batch 230 Loss 0.0357 Accuracy 0.9288 AUC 0.5045\n","Epoch 1 Batch 240 Loss 0.0352 Accuracy 0.9293 AUC 0.5034\n","Epoch 1 Batch 250 Loss 0.0351 Accuracy 0.9291 AUC 0.5025\n","Epoch 1 Batch 260 Loss 0.0347 Accuracy 0.9294 AUC 0.5032\n","Epoch 1 Batch 270 Loss 0.0343 Accuracy 0.9296 AUC 0.5028\n","Epoch 1 Batch 280 Loss 0.0339 Accuracy 0.9304 AUC 0.5020\n","Epoch 1 Batch 290 Loss 0.0336 Accuracy 0.9304 AUC 0.5034\n","Epoch 1 Batch 300 Loss 0.0332 Accuracy 0.9309 AUC 0.5028\n","Epoch 1 Batch 310 Loss 0.0330 Accuracy 0.9306 AUC 0.5037\n","Epoch 1 Batch 320 Loss 0.0328 Accuracy 0.9305 AUC 0.5036\n","Epoch 1 Batch 330 Loss 0.0326 Accuracy 0.9306 AUC 0.5043\n","Epoch 1 Batch 340 Loss 0.0323 Accuracy 0.9308 AUC 0.5028\n","Epoch 1 Batch 350 Loss 0.0322 Accuracy 0.9308 AUC 0.5034\n","Epoch 1 Batch 360 Loss 0.0320 Accuracy 0.9307 AUC 0.5035\n","Epoch 1 Batch 370 Loss 0.0319 Accuracy 0.9304 AUC 0.5040\n","Epoch 1 Batch 380 Loss 0.0317 Accuracy 0.9307 AUC 0.5029\n","Epoch 1 Batch 390 Loss 0.0316 Accuracy 0.9305 AUC 0.5031\n","Epoch 1 Batch 400 Loss 0.0315 Accuracy 0.9306 AUC 0.5027\n","Epoch 1 Batch 410 Loss 0.0312 Accuracy 0.9308 AUC 0.5027\n","Epoch 1 Batch 420 Loss 0.0310 Accuracy 0.9310 AUC 0.5037\n","Epoch 1 Batch 430 Loss 0.0308 Accuracy 0.9313 AUC 0.5040\n","Epoch 1 Batch 440 Loss 0.0307 Accuracy 0.9314 AUC 0.5042\n","Epoch 1 Batch 450 Loss 0.0306 Accuracy 0.9312 AUC 0.5054\n","Epoch 1 Batch 460 Loss 0.0305 Accuracy 0.9312 AUC 0.5044\n","Epoch 1 Batch 470 Loss 0.0304 Accuracy 0.9311 AUC 0.5041\n","Epoch 1 Batch 480 Loss 0.0303 Accuracy 0.9311 AUC 0.5048\n","Epoch 1 Batch 490 Loss 0.0301 Accuracy 0.9314 AUC 0.5045\n","Epoch 1 Batch 500 Loss 0.0300 Accuracy 0.9313 AUC 0.5041\n","Epoch 1 Batch 510 Loss 0.0299 Accuracy 0.9315 AUC 0.5048\n","Epoch 1 Batch 520 Loss 0.0299 Accuracy 0.9311 AUC 0.5057\n","Epoch 1 Batch 530 Loss 0.0298 Accuracy 0.9312 AUC 0.5049\n","Epoch 1 Batch 540 Loss 0.0297 Accuracy 0.9312 AUC 0.5058\n","Epoch 1 Batch 550 Loss 0.0296 Accuracy 0.9313 AUC 0.5055\n","Epoch 1 Batch 560 Loss 0.0295 Accuracy 0.9313 AUC 0.5056\n","Epoch 1 Batch 570 Loss 0.0295 Accuracy 0.9313 AUC 0.5046\n","Epoch 1 Batch 580 Loss 0.0294 Accuracy 0.9314 AUC 0.5042\n","Epoch 1 Batch 590 Loss 0.0293 Accuracy 0.9312 AUC 0.5052\n","Epoch 1 Batch 600 Loss 0.0293 Accuracy 0.9312 AUC 0.5046\n","Epoch 1 Batch 610 Loss 0.0292 Accuracy 0.9312 AUC 0.5051\n","Epoch 1 Batch 620 Loss 0.0291 Accuracy 0.9313 AUC 0.5045\n","Epoch 1 Batch 630 Loss 0.0291 Accuracy 0.9313 AUC 0.5041\n","Epoch 1 Batch 640 Loss 0.0291 Accuracy 0.9311 AUC 0.5049\n","Epoch 1 Batch 650 Loss 0.0290 Accuracy 0.9313 AUC 0.5048\n","Epoch 1 Batch 660 Loss 0.0289 Accuracy 0.9313 AUC 0.5038\n","Epoch 1 Batch 670 Loss 0.0289 Accuracy 0.9311 AUC 0.5035\n","Epoch 1 Batch 680 Loss 0.0289 Accuracy 0.9308 AUC 0.5047\n","Epoch 1 Batch 690 Loss 0.0289 Accuracy 0.9306 AUC 0.5055\n","Epoch 1 Batch 700 Loss 0.0289 Accuracy 0.9306 AUC 0.5062\n","Epoch 1 Batch 710 Loss 0.0288 Accuracy 0.9307 AUC 0.5059\n","Epoch 1 Batch 720 Loss 0.0287 Accuracy 0.9308 AUC 0.5061\n","Epoch 1 Batch 730 Loss 0.0286 Accuracy 0.9311 AUC 0.5064\n","Epoch 1 Batch 740 Loss 0.0285 Accuracy 0.9310 AUC 0.5071\n","Epoch 1 Batch 750 Loss 0.0286 Accuracy 0.9307 AUC 0.5082\n","Epoch 1 Batch 760 Loss 0.0286 Accuracy 0.9306 AUC 0.5079\n","Epoch 1 Batch 770 Loss 0.0285 Accuracy 0.9306 AUC 0.5077\n","Epoch 1 Batch 780 Loss 0.0285 Accuracy 0.9306 AUC 0.5074\n","Epoch 1 Batch 790 Loss 0.0284 Accuracy 0.9308 AUC 0.5071\n","Epoch 1 Batch 800 Loss 0.0283 Accuracy 0.9309 AUC 0.5067\n","Epoch 1 Batch 810 Loss 0.0283 Accuracy 0.9309 AUC 0.5070\n","Epoch 1 Batch 820 Loss 0.0283 Accuracy 0.9308 AUC 0.5063\n","Epoch 1 Batch 830 Loss 0.0282 Accuracy 0.9310 AUC 0.5062\n","Epoch 1 Batch 840 Loss 0.0281 Accuracy 0.9311 AUC 0.5063\n","Epoch 1 Batch 850 Loss 0.0281 Accuracy 0.9310 AUC 0.5058\n","Epoch 1 Batch 860 Loss 0.0281 Accuracy 0.9310 AUC 0.5052\n","Epoch 1 Batch 870 Loss 0.0281 Accuracy 0.9311 AUC 0.5045\n","Epoch 1 Batch 880 Loss 0.0281 Accuracy 0.9309 AUC 0.5051\n","Epoch 1 Batch 890 Loss 0.0280 Accuracy 0.9309 AUC 0.5054\n","Epoch 1 Batch 900 Loss 0.0279 Accuracy 0.9311 AUC 0.5049\n","Epoch 1 Batch 910 Loss 0.0279 Accuracy 0.9312 AUC 0.5047\n","Epoch 1 Batch 920 Loss 0.0278 Accuracy 0.9313 AUC 0.5046\n","Epoch 1 Batch 930 Loss 0.0278 Accuracy 0.9312 AUC 0.5047\n","Epoch 1 Batch 940 Loss 0.0278 Accuracy 0.9313 AUC 0.5043\n","Epoch 1 Batch 950 Loss 0.0277 Accuracy 0.9312 AUC 0.5044\n","Epoch 1 Batch 960 Loss 0.0277 Accuracy 0.9311 AUC 0.5048\n","Epoch 1 Batch 970 Loss 0.0277 Accuracy 0.9312 AUC 0.5046\n","Epoch 1 Batch 980 Loss 0.0276 Accuracy 0.9313 AUC 0.5042\n","Epoch 1 Batch 990 Loss 0.0276 Accuracy 0.9313 AUC 0.5045\n","Epoch 1 Batch 1000 Loss 0.0276 Accuracy 0.9313 AUC 0.5040\n","Epoch 1 Batch 1010 Loss 0.0276 Accuracy 0.9311 AUC 0.5047\n","Epoch 1 Batch 1020 Loss 0.0276 Accuracy 0.9311 AUC 0.5048\n","Epoch 1 Batch 1030 Loss 0.0275 Accuracy 0.9311 AUC 0.5040\n","Epoch 1 Batch 1040 Loss 0.0275 Accuracy 0.9311 AUC 0.5042\n","Epoch 1 Batch 1050 Loss 0.0275 Accuracy 0.9310 AUC 0.5037\n","Epoch 1 Batch 1060 Loss 0.0275 Accuracy 0.9310 AUC 0.5036\n","Epoch 1 Batch 1070 Loss 0.0275 Accuracy 0.9311 AUC 0.5036\n","Epoch 1 Batch 1080 Loss 0.0274 Accuracy 0.9311 AUC 0.5034\n","Epoch 1 Batch 1090 Loss 0.0274 Accuracy 0.9312 AUC 0.5031\n","Epoch 1 Batch 1100 Loss 0.0274 Accuracy 0.9312 AUC 0.5030\n","Epoch 1 Batch 1110 Loss 0.0273 Accuracy 0.9312 AUC 0.5035\n","Epoch 1 Batch 1120 Loss 0.0272 Accuracy 0.9314 AUC 0.5039\n","Epoch 1 Batch 1130 Loss 0.0272 Accuracy 0.9316 AUC 0.5042\n","Epoch 1 Batch 1140 Loss 0.0272 Accuracy 0.9316 AUC 0.5038\n","Epoch 1 Batch 1150 Loss 0.0271 Accuracy 0.9318 AUC 0.5040\n","Epoch 1 Batch 1160 Loss 0.0271 Accuracy 0.9316 AUC 0.5042\n","Epoch 1 Batch 1170 Loss 0.0271 Accuracy 0.9315 AUC 0.5046\n","Epoch 1 Batch 1180 Loss 0.0271 Accuracy 0.9315 AUC 0.5047\n","Epoch 1 Batch 1190 Loss 0.0271 Accuracy 0.9315 AUC 0.5048\n","Epoch 1 Batch 1200 Loss 0.0271 Accuracy 0.9314 AUC 0.5051\n","Epoch 1 Batch 1210 Loss 0.0271 Accuracy 0.9313 AUC 0.5050\n","Epoch 1 Batch 1220 Loss 0.0270 Accuracy 0.9314 AUC 0.5052\n","Epoch 1 Batch 1230 Loss 0.0270 Accuracy 0.9315 AUC 0.5053\n","Epoch 1 Batch 1240 Loss 0.0270 Accuracy 0.9315 AUC 0.5049\n","Epoch 1 Batch 1250 Loss 0.0270 Accuracy 0.9316 AUC 0.5047\n","Epoch 1 Batch 1260 Loss 0.0269 Accuracy 0.9316 AUC 0.5049\n","Epoch 1 Batch 1270 Loss 0.0269 Accuracy 0.9317 AUC 0.5049\n","Epoch 1 Batch 1280 Loss 0.0268 Accuracy 0.9318 AUC 0.5050\n","Epoch 1 Batch 1290 Loss 0.0268 Accuracy 0.9318 AUC 0.5052\n","Epoch 1 Batch 1300 Loss 0.0268 Accuracy 0.9318 AUC 0.5052\n","Epoch 1 Batch 1310 Loss 0.0268 Accuracy 0.9318 AUC 0.5054\n","Epoch 1 Batch 1320 Loss 0.0268 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1330 Loss 0.0268 Accuracy 0.9318 AUC 0.5052\n","Epoch 1 Batch 1340 Loss 0.0268 Accuracy 0.9317 AUC 0.5055\n","Epoch 1 Batch 1350 Loss 0.0268 Accuracy 0.9316 AUC 0.5054\n","Epoch 1 Batch 1360 Loss 0.0268 Accuracy 0.9316 AUC 0.5055\n","Epoch 1 Batch 1370 Loss 0.0267 Accuracy 0.9317 AUC 0.5055\n","Epoch 1 Batch 1380 Loss 0.0267 Accuracy 0.9317 AUC 0.5054\n","Epoch 1 Batch 1390 Loss 0.0267 Accuracy 0.9318 AUC 0.5053\n","Epoch 1 Batch 1400 Loss 0.0266 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1410 Loss 0.0266 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1420 Loss 0.0266 Accuracy 0.9320 AUC 0.5051\n","Epoch 1 Batch 1430 Loss 0.0266 Accuracy 0.9319 AUC 0.5049\n","Epoch 1 Batch 1440 Loss 0.0266 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1450 Loss 0.0266 Accuracy 0.9319 AUC 0.5054\n","Epoch 1 Batch 1460 Loss 0.0265 Accuracy 0.9320 AUC 0.5056\n","Epoch 1 Batch 1470 Loss 0.0265 Accuracy 0.9321 AUC 0.5055\n","Epoch 1 Batch 1480 Loss 0.0265 Accuracy 0.9321 AUC 0.5054\n","Epoch 1 Batch 1490 Loss 0.0265 Accuracy 0.9320 AUC 0.5057\n","Epoch 1 Batch 1500 Loss 0.0264 Accuracy 0.9321 AUC 0.5057\n","Epoch 1 Batch 1510 Loss 0.0264 Accuracy 0.9321 AUC 0.5053\n","Epoch 1 Batch 1520 Loss 0.0264 Accuracy 0.9321 AUC 0.5050\n","Epoch 1 Batch 1530 Loss 0.0264 Accuracy 0.9321 AUC 0.5047\n","Epoch 1 Batch 1540 Loss 0.0264 Accuracy 0.9320 AUC 0.5053\n","Epoch 1 Batch 1550 Loss 0.0264 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1560 Loss 0.0264 Accuracy 0.9319 AUC 0.5053\n","Epoch 1 Batch 1570 Loss 0.0264 Accuracy 0.9319 AUC 0.5050\n","Epoch 1 Batch 1580 Loss 0.0264 Accuracy 0.9319 AUC 0.5051\n","Epoch 1 Batch 1590 Loss 0.0264 Accuracy 0.9320 AUC 0.5049\n","Epoch 1 Batch 1600 Loss 0.0264 Accuracy 0.9320 AUC 0.5053\n","Epoch 1 Batch 1610 Loss 0.0263 Accuracy 0.9320 AUC 0.5049\n","Epoch 1 Batch 1620 Loss 0.0263 Accuracy 0.9320 AUC 0.5048\n","Epoch 1 Batch 1630 Loss 0.0263 Accuracy 0.9320 AUC 0.5045\n","Epoch 1 Batch 1640 Loss 0.0263 Accuracy 0.9320 AUC 0.5046\n","Epoch 1 Batch 1650 Loss 0.0263 Accuracy 0.9321 AUC 0.5044\n","Epoch 1 Batch 1660 Loss 0.0262 Accuracy 0.9321 AUC 0.5044\n","Epoch 1 Batch 1670 Loss 0.0262 Accuracy 0.9322 AUC 0.5045\n","Epoch 1 Batch 1680 Loss 0.0262 Accuracy 0.9321 AUC 0.5044\n","Epoch 1 Batch 1690 Loss 0.0262 Accuracy 0.9321 AUC 0.5044\n","Epoch 1 Batch 1700 Loss 0.0262 Accuracy 0.9320 AUC 0.5044\n","Epoch 1 Batch 1710 Loss 0.0262 Accuracy 0.9320 AUC 0.5041\n","Epoch 1 Batch 1720 Loss 0.0262 Accuracy 0.9319 AUC 0.5037\n","Epoch 1 Batch 1730 Loss 0.0262 Accuracy 0.9320 AUC 0.5037\n","Epoch 1 Batch 1740 Loss 0.0262 Accuracy 0.9319 AUC 0.5033\n","Epoch 1 Batch 1750 Loss 0.0262 Accuracy 0.9319 AUC 0.5036\n","Epoch 1 Batch 1760 Loss 0.0262 Accuracy 0.9319 AUC 0.5036\n","Epoch 1 Batch 1770 Loss 0.0262 Accuracy 0.9319 AUC 0.5036\n","Epoch 1 Batch 1780 Loss 0.0262 Accuracy 0.9320 AUC 0.5035\n","Epoch 1 Batch 1790 Loss 0.0261 Accuracy 0.9321 AUC 0.5035\n","Epoch 1 Batch 1800 Loss 0.0261 Accuracy 0.9321 AUC 0.5036\n","Epoch 1 Batch 1810 Loss 0.0261 Accuracy 0.9321 AUC 0.5033\n","Epoch 1 Batch 1820 Loss 0.0261 Accuracy 0.9320 AUC 0.5032\n","Epoch 1 Batch 1830 Loss 0.0261 Accuracy 0.9320 AUC 0.5033\n","Epoch 1 Batch 1840 Loss 0.0261 Accuracy 0.9320 AUC 0.5032\n","Epoch 1 Batch 1850 Loss 0.0261 Accuracy 0.9320 AUC 0.5029\n","Epoch 1 Batch 1860 Loss 0.0261 Accuracy 0.9320 AUC 0.5026\n","Epoch 1 Batch 1870 Loss 0.0261 Accuracy 0.9321 AUC 0.5026\n","Epoch 1 Batch 1880 Loss 0.0261 Accuracy 0.9321 AUC 0.5028\n","Epoch 1 Batch 1890 Loss 0.0261 Accuracy 0.9320 AUC 0.5029\n","Epoch 1 Batch 1900 Loss 0.0261 Accuracy 0.9320 AUC 0.5034\n","Epoch 1 Batch 1910 Loss 0.0261 Accuracy 0.9319 AUC 0.5032\n","Epoch 1 Batch 1920 Loss 0.0261 Accuracy 0.9320 AUC 0.5029\n","Epoch 1 Batch 1930 Loss 0.0261 Accuracy 0.9320 AUC 0.5028\n","Epoch 1 Batch 1940 Loss 0.0260 Accuracy 0.9320 AUC 0.5026\n","Epoch 1 Batch 1950 Loss 0.0260 Accuracy 0.9321 AUC 0.5027\n","Epoch 1 Batch 1960 Loss 0.0260 Accuracy 0.9321 AUC 0.5026\n","Epoch 1 Batch 1970 Loss 0.0260 Accuracy 0.9321 AUC 0.5028\n","Epoch 1 Batch 1980 Loss 0.0260 Accuracy 0.9321 AUC 0.5027\n","Epoch 1 Batch 1990 Loss 0.0260 Accuracy 0.9321 AUC 0.5029\n","Epoch 1 Batch 2000 Loss 0.0260 Accuracy 0.9322 AUC 0.5027\n","Epoch 1 Batch 2010 Loss 0.0260 Accuracy 0.9321 AUC 0.5025\n","Epoch 1 Batch 2020 Loss 0.0259 Accuracy 0.9322 AUC 0.5022\n","Epoch 1 Batch 2030 Loss 0.0259 Accuracy 0.9321 AUC 0.5023\n","Epoch 1 Batch 2040 Loss 0.0259 Accuracy 0.9321 AUC 0.5021\n","Epoch 1 Batch 2050 Loss 0.0259 Accuracy 0.9321 AUC 0.5025\n","Epoch 1 Batch 2060 Loss 0.0259 Accuracy 0.9321 AUC 0.5023\n","Epoch 1 Batch 2070 Loss 0.0259 Accuracy 0.9321 AUC 0.5025\n","Epoch 1 Batch 2080 Loss 0.0259 Accuracy 0.9321 AUC 0.5029\n","Epoch 1 Batch 2090 Loss 0.0259 Accuracy 0.9321 AUC 0.5030\n","Epoch 1 Batch 2100 Loss 0.0259 Accuracy 0.9321 AUC 0.5029\n","Epoch 1 Loss 0.0259 Accuracy 0.9321\n","Time taken for 1 epoch: 719.7908687591553 secs\n","\n","Epoch 2 Batch 0 Loss 0.0170 Accuracy 0.9531 AUC 0.8087\n","Epoch 2 Batch 10 Loss 0.0238 Accuracy 0.9332 AUC 0.5330\n","Epoch 2 Batch 20 Loss 0.0258 Accuracy 0.9256 AUC 0.5281\n","Epoch 2 Batch 30 Loss 0.0242 Accuracy 0.9325 AUC 0.5168\n","Epoch 2 Batch 40 Loss 0.0249 Accuracy 0.9303 AUC 0.5093\n","Epoch 2 Batch 50 Loss 0.0247 Accuracy 0.9314 AUC 0.5015\n","Epoch 2 Batch 60 Loss 0.0252 Accuracy 0.9293 AUC 0.5079\n","Epoch 2 Batch 70 Loss 0.0250 Accuracy 0.9298 AUC 0.5088\n","Epoch 2 Batch 80 Loss 0.0252 Accuracy 0.9290 AUC 0.5078\n","Epoch 2 Batch 90 Loss 0.0250 Accuracy 0.9296 AUC 0.5132\n","Epoch 2 Batch 100 Loss 0.0250 Accuracy 0.9299 AUC 0.5094\n","Epoch 2 Batch 110 Loss 0.0252 Accuracy 0.9293 AUC 0.5090\n","Epoch 2 Batch 120 Loss 0.0249 Accuracy 0.9301 AUC 0.5104\n","Epoch 2 Batch 130 Loss 0.0249 Accuracy 0.9302 AUC 0.5121\n","Epoch 2 Batch 140 Loss 0.0248 Accuracy 0.9305 AUC 0.5136\n","Epoch 2 Batch 150 Loss 0.0248 Accuracy 0.9308 AUC 0.5089\n","Epoch 2 Batch 160 Loss 0.0249 Accuracy 0.9303 AUC 0.5093\n","Epoch 2 Batch 170 Loss 0.0250 Accuracy 0.9301 AUC 0.5055\n","Epoch 2 Batch 180 Loss 0.0249 Accuracy 0.9302 AUC 0.5053\n","Epoch 2 Batch 190 Loss 0.0248 Accuracy 0.9305 AUC 0.5057\n","Epoch 2 Batch 200 Loss 0.0249 Accuracy 0.9301 AUC 0.5073\n","Epoch 2 Batch 210 Loss 0.0247 Accuracy 0.9310 AUC 0.5101\n","Epoch 2 Batch 220 Loss 0.0246 Accuracy 0.9314 AUC 0.5066\n","Epoch 2 Batch 230 Loss 0.0244 Accuracy 0.9323 AUC 0.5100\n","Epoch 2 Batch 240 Loss 0.0243 Accuracy 0.9326 AUC 0.5122\n","Epoch 2 Batch 250 Loss 0.0244 Accuracy 0.9323 AUC 0.5132\n","Epoch 2 Batch 260 Loss 0.0244 Accuracy 0.9324 AUC 0.5132\n","Epoch 2 Batch 270 Loss 0.0243 Accuracy 0.9325 AUC 0.5095\n","Epoch 2 Batch 280 Loss 0.0242 Accuracy 0.9332 AUC 0.5103\n","Epoch 2 Batch 290 Loss 0.0242 Accuracy 0.9332 AUC 0.5105\n","Epoch 2 Batch 300 Loss 0.0241 Accuracy 0.9335 AUC 0.5111\n","Epoch 2 Batch 310 Loss 0.0242 Accuracy 0.9332 AUC 0.5092\n","Epoch 2 Batch 320 Loss 0.0242 Accuracy 0.9330 AUC 0.5080\n","Epoch 2 Batch 330 Loss 0.0242 Accuracy 0.9330 AUC 0.5086\n","Epoch 2 Batch 340 Loss 0.0242 Accuracy 0.9331 AUC 0.5078\n","Epoch 2 Batch 350 Loss 0.0242 Accuracy 0.9331 AUC 0.5070\n","Epoch 2 Batch 360 Loss 0.0243 Accuracy 0.9329 AUC 0.5064\n","Epoch 2 Batch 370 Loss 0.0244 Accuracy 0.9325 AUC 0.5048\n","Epoch 2 Batch 380 Loss 0.0243 Accuracy 0.9328 AUC 0.5045\n","Epoch 2 Batch 390 Loss 0.0243 Accuracy 0.9326 AUC 0.5054\n","Epoch 2 Batch 400 Loss 0.0243 Accuracy 0.9326 AUC 0.5055\n","Epoch 2 Batch 410 Loss 0.0243 Accuracy 0.9327 AUC 0.5062\n","Epoch 2 Batch 420 Loss 0.0242 Accuracy 0.9329 AUC 0.5080\n","Epoch 2 Batch 430 Loss 0.0241 Accuracy 0.9331 AUC 0.5080\n","Epoch 2 Batch 440 Loss 0.0241 Accuracy 0.9332 AUC 0.5103\n","Epoch 2 Batch 450 Loss 0.0242 Accuracy 0.9330 AUC 0.5115\n","Epoch 2 Batch 460 Loss 0.0242 Accuracy 0.9330 AUC 0.5111\n","Epoch 2 Batch 470 Loss 0.0242 Accuracy 0.9328 AUC 0.5104\n","Epoch 2 Batch 480 Loss 0.0242 Accuracy 0.9328 AUC 0.5096\n","Epoch 2 Batch 490 Loss 0.0242 Accuracy 0.9330 AUC 0.5086\n","Epoch 2 Batch 500 Loss 0.0242 Accuracy 0.9329 AUC 0.5071\n","Epoch 2 Batch 510 Loss 0.0242 Accuracy 0.9330 AUC 0.5084\n","Epoch 2 Batch 520 Loss 0.0243 Accuracy 0.9326 AUC 0.5087\n","Epoch 2 Batch 530 Loss 0.0242 Accuracy 0.9327 AUC 0.5084\n","Epoch 2 Batch 540 Loss 0.0243 Accuracy 0.9327 AUC 0.5074\n","Epoch 2 Batch 550 Loss 0.0243 Accuracy 0.9328 AUC 0.5071\n","Epoch 2 Batch 560 Loss 0.0243 Accuracy 0.9327 AUC 0.5066\n","Epoch 2 Batch 570 Loss 0.0243 Accuracy 0.9327 AUC 0.5060\n","Epoch 2 Batch 580 Loss 0.0243 Accuracy 0.9328 AUC 0.5059\n","Epoch 2 Batch 590 Loss 0.0243 Accuracy 0.9326 AUC 0.5057\n","Epoch 2 Batch 600 Loss 0.0243 Accuracy 0.9325 AUC 0.5053\n","Epoch 2 Batch 610 Loss 0.0243 Accuracy 0.9325 AUC 0.5050\n","Epoch 2 Batch 620 Loss 0.0243 Accuracy 0.9325 AUC 0.5055\n","Epoch 2 Batch 630 Loss 0.0243 Accuracy 0.9326 AUC 0.5046\n","Epoch 2 Batch 640 Loss 0.0244 Accuracy 0.9323 AUC 0.5040\n","Epoch 2 Batch 650 Loss 0.0243 Accuracy 0.9325 AUC 0.5043\n","Epoch 2 Batch 660 Loss 0.0243 Accuracy 0.9325 AUC 0.5038\n","Epoch 2 Batch 670 Loss 0.0244 Accuracy 0.9323 AUC 0.5039\n","Epoch 2 Batch 680 Loss 0.0244 Accuracy 0.9320 AUC 0.5038\n","Epoch 2 Batch 690 Loss 0.0245 Accuracy 0.9317 AUC 0.5039\n","Epoch 2 Batch 700 Loss 0.0245 Accuracy 0.9317 AUC 0.5048\n","Epoch 2 Batch 710 Loss 0.0245 Accuracy 0.9318 AUC 0.5052\n","Epoch 2 Batch 720 Loss 0.0245 Accuracy 0.9319 AUC 0.5052\n","Epoch 2 Batch 730 Loss 0.0244 Accuracy 0.9322 AUC 0.5064\n","Epoch 2 Batch 740 Loss 0.0244 Accuracy 0.9320 AUC 0.5076\n","Epoch 2 Batch 750 Loss 0.0245 Accuracy 0.9318 AUC 0.5075\n","Epoch 2 Batch 760 Loss 0.0245 Accuracy 0.9316 AUC 0.5076\n","Epoch 2 Batch 770 Loss 0.0245 Accuracy 0.9316 AUC 0.5073\n","Epoch 2 Batch 780 Loss 0.0245 Accuracy 0.9316 AUC 0.5075\n","Epoch 2 Batch 790 Loss 0.0244 Accuracy 0.9318 AUC 0.5087\n","Epoch 2 Batch 800 Loss 0.0244 Accuracy 0.9319 AUC 0.5083\n","Epoch 2 Batch 810 Loss 0.0244 Accuracy 0.9319 AUC 0.5088\n","Epoch 2 Batch 820 Loss 0.0244 Accuracy 0.9318 AUC 0.5093\n","Epoch 2 Batch 830 Loss 0.0244 Accuracy 0.9320 AUC 0.5096\n","Epoch 2 Batch 840 Loss 0.0244 Accuracy 0.9320 AUC 0.5099\n","Epoch 2 Batch 850 Loss 0.0244 Accuracy 0.9319 AUC 0.5101\n","Epoch 2 Batch 860 Loss 0.0244 Accuracy 0.9319 AUC 0.5100\n","Epoch 2 Batch 870 Loss 0.0244 Accuracy 0.9320 AUC 0.5105\n","Epoch 2 Batch 880 Loss 0.0244 Accuracy 0.9318 AUC 0.5108\n","Epoch 2 Batch 890 Loss 0.0244 Accuracy 0.9318 AUC 0.5105\n","Epoch 2 Batch 900 Loss 0.0244 Accuracy 0.9320 AUC 0.5109\n","Epoch 2 Batch 910 Loss 0.0244 Accuracy 0.9320 AUC 0.5110\n","Epoch 2 Batch 920 Loss 0.0243 Accuracy 0.9321 AUC 0.5108\n","Epoch 2 Batch 930 Loss 0.0243 Accuracy 0.9321 AUC 0.5108\n","Epoch 2 Batch 940 Loss 0.0243 Accuracy 0.9321 AUC 0.5104\n","Epoch 2 Batch 950 Loss 0.0243 Accuracy 0.9321 AUC 0.5114\n","Epoch 2 Batch 960 Loss 0.0244 Accuracy 0.9319 AUC 0.5118\n","Epoch 2 Batch 970 Loss 0.0243 Accuracy 0.9320 AUC 0.5119\n","Epoch 2 Batch 980 Loss 0.0243 Accuracy 0.9321 AUC 0.5109\n","Epoch 2 Batch 990 Loss 0.0243 Accuracy 0.9321 AUC 0.5104\n","Epoch 2 Batch 1000 Loss 0.0243 Accuracy 0.9321 AUC 0.5105\n","Epoch 2 Batch 1010 Loss 0.0244 Accuracy 0.9319 AUC 0.5110\n","Epoch 2 Batch 1020 Loss 0.0244 Accuracy 0.9318 AUC 0.5116\n","Epoch 2 Batch 1030 Loss 0.0244 Accuracy 0.9319 AUC 0.5114\n","Epoch 2 Batch 1040 Loss 0.0244 Accuracy 0.9318 AUC 0.5111\n","Epoch 2 Batch 1050 Loss 0.0244 Accuracy 0.9318 AUC 0.5108\n","Epoch 2 Batch 1060 Loss 0.0244 Accuracy 0.9318 AUC 0.5104\n","Epoch 2 Batch 1070 Loss 0.0244 Accuracy 0.9318 AUC 0.5104\n","Epoch 2 Batch 1080 Loss 0.0244 Accuracy 0.9318 AUC 0.5108\n","Epoch 2 Batch 1090 Loss 0.0244 Accuracy 0.9319 AUC 0.5108\n","Epoch 2 Batch 1100 Loss 0.0243 Accuracy 0.9320 AUC 0.5111\n","Epoch 2 Batch 1110 Loss 0.0243 Accuracy 0.9319 AUC 0.5113\n","Epoch 2 Batch 1120 Loss 0.0243 Accuracy 0.9321 AUC 0.5120\n","Epoch 2 Batch 1130 Loss 0.0242 Accuracy 0.9323 AUC 0.5130\n","Epoch 2 Batch 1140 Loss 0.0242 Accuracy 0.9323 AUC 0.5134\n","Epoch 2 Batch 1150 Loss 0.0242 Accuracy 0.9325 AUC 0.5138\n","Epoch 2 Batch 1160 Loss 0.0242 Accuracy 0.9323 AUC 0.5142\n","Epoch 2 Batch 1170 Loss 0.0243 Accuracy 0.9322 AUC 0.5150\n","Epoch 2 Batch 1180 Loss 0.0243 Accuracy 0.9321 AUC 0.5151\n","Epoch 2 Batch 1190 Loss 0.0243 Accuracy 0.9322 AUC 0.5146\n","Epoch 2 Batch 1200 Loss 0.0243 Accuracy 0.9320 AUC 0.5150\n","Epoch 2 Batch 1210 Loss 0.0243 Accuracy 0.9320 AUC 0.5154\n","Epoch 2 Batch 1220 Loss 0.0243 Accuracy 0.9320 AUC 0.5154\n","Epoch 2 Batch 1230 Loss 0.0243 Accuracy 0.9321 AUC 0.5157\n","Epoch 2 Batch 1240 Loss 0.0243 Accuracy 0.9321 AUC 0.5157\n","Epoch 2 Batch 1250 Loss 0.0242 Accuracy 0.9322 AUC 0.5157\n","Epoch 2 Batch 1260 Loss 0.0242 Accuracy 0.9322 AUC 0.5162\n","Epoch 2 Batch 1270 Loss 0.0242 Accuracy 0.9324 AUC 0.5160\n","Epoch 2 Batch 1280 Loss 0.0242 Accuracy 0.9324 AUC 0.5159\n","Epoch 2 Batch 1290 Loss 0.0242 Accuracy 0.9324 AUC 0.5162\n","Epoch 2 Batch 1300 Loss 0.0242 Accuracy 0.9324 AUC 0.5157\n","Epoch 2 Batch 1310 Loss 0.0242 Accuracy 0.9324 AUC 0.5158\n","Epoch 2 Batch 1320 Loss 0.0242 Accuracy 0.9325 AUC 0.5158\n","Epoch 2 Batch 1330 Loss 0.0242 Accuracy 0.9324 AUC 0.5162\n","Epoch 2 Batch 1340 Loss 0.0242 Accuracy 0.9323 AUC 0.5166\n","Epoch 2 Batch 1350 Loss 0.0242 Accuracy 0.9322 AUC 0.5167\n","Epoch 2 Batch 1360 Loss 0.0242 Accuracy 0.9322 AUC 0.5167\n","Epoch 2 Batch 1370 Loss 0.0242 Accuracy 0.9323 AUC 0.5173\n","Epoch 2 Batch 1380 Loss 0.0242 Accuracy 0.9323 AUC 0.5178\n","Epoch 2 Batch 1390 Loss 0.0242 Accuracy 0.9324 AUC 0.5183\n","Epoch 2 Batch 1400 Loss 0.0241 Accuracy 0.9325 AUC 0.5182\n","Epoch 2 Batch 1410 Loss 0.0242 Accuracy 0.9324 AUC 0.5184\n","Epoch 2 Batch 1420 Loss 0.0241 Accuracy 0.9326 AUC 0.5186\n","Epoch 2 Batch 1430 Loss 0.0241 Accuracy 0.9325 AUC 0.5186\n","Epoch 2 Batch 1440 Loss 0.0242 Accuracy 0.9324 AUC 0.5189\n","Epoch 2 Batch 1450 Loss 0.0242 Accuracy 0.9324 AUC 0.5190\n","Epoch 2 Batch 1460 Loss 0.0241 Accuracy 0.9326 AUC 0.5190\n","Epoch 2 Batch 1470 Loss 0.0241 Accuracy 0.9326 AUC 0.5187\n","Epoch 2 Batch 1480 Loss 0.0241 Accuracy 0.9327 AUC 0.5182\n","Epoch 2 Batch 1490 Loss 0.0241 Accuracy 0.9325 AUC 0.5186\n","Epoch 2 Batch 1500 Loss 0.0241 Accuracy 0.9326 AUC 0.5187\n","Epoch 2 Batch 1510 Loss 0.0241 Accuracy 0.9326 AUC 0.5184\n","Epoch 2 Batch 1520 Loss 0.0241 Accuracy 0.9327 AUC 0.5182\n","Epoch 2 Batch 1530 Loss 0.0241 Accuracy 0.9326 AUC 0.5184\n","Epoch 2 Batch 1540 Loss 0.0241 Accuracy 0.9325 AUC 0.5186\n","Epoch 2 Batch 1550 Loss 0.0242 Accuracy 0.9324 AUC 0.5184\n","Epoch 2 Batch 1560 Loss 0.0242 Accuracy 0.9324 AUC 0.5183\n","Epoch 2 Batch 1570 Loss 0.0242 Accuracy 0.9324 AUC 0.5183\n","Epoch 2 Batch 1580 Loss 0.0242 Accuracy 0.9324 AUC 0.5182\n","Epoch 2 Batch 1590 Loss 0.0241 Accuracy 0.9325 AUC 0.5180\n","Epoch 2 Batch 1600 Loss 0.0241 Accuracy 0.9325 AUC 0.5182\n","Epoch 2 Batch 1610 Loss 0.0241 Accuracy 0.9325 AUC 0.5182\n","Epoch 2 Batch 1620 Loss 0.0241 Accuracy 0.9325 AUC 0.5183\n","Epoch 2 Batch 1630 Loss 0.0241 Accuracy 0.9324 AUC 0.5182\n","Epoch 2 Batch 1640 Loss 0.0241 Accuracy 0.9325 AUC 0.5182\n","Epoch 2 Batch 1650 Loss 0.0241 Accuracy 0.9326 AUC 0.5186\n","Epoch 2 Batch 1660 Loss 0.0241 Accuracy 0.9326 AUC 0.5187\n","Epoch 2 Batch 1670 Loss 0.0241 Accuracy 0.9326 AUC 0.5188\n","Epoch 2 Batch 1680 Loss 0.0241 Accuracy 0.9326 AUC 0.5192\n","Epoch 2 Batch 1690 Loss 0.0241 Accuracy 0.9325 AUC 0.5192\n","Epoch 2 Batch 1700 Loss 0.0241 Accuracy 0.9325 AUC 0.5198\n","Epoch 2 Batch 1710 Loss 0.0241 Accuracy 0.9324 AUC 0.5198\n","Epoch 2 Batch 1720 Loss 0.0241 Accuracy 0.9324 AUC 0.5197\n","Epoch 2 Batch 1730 Loss 0.0241 Accuracy 0.9324 AUC 0.5197\n","Epoch 2 Batch 1740 Loss 0.0241 Accuracy 0.9324 AUC 0.5199\n","Epoch 2 Batch 1750 Loss 0.0241 Accuracy 0.9324 AUC 0.5201\n","Epoch 2 Batch 1760 Loss 0.0241 Accuracy 0.9324 AUC 0.5203\n","Epoch 2 Batch 1770 Loss 0.0241 Accuracy 0.9323 AUC 0.5200\n","Epoch 2 Batch 1780 Loss 0.0241 Accuracy 0.9324 AUC 0.5199\n","Epoch 2 Batch 1790 Loss 0.0241 Accuracy 0.9325 AUC 0.5198\n","Epoch 2 Batch 1800 Loss 0.0241 Accuracy 0.9325 AUC 0.5197\n","Epoch 2 Batch 1810 Loss 0.0241 Accuracy 0.9325 AUC 0.5193\n","Epoch 2 Batch 1820 Loss 0.0241 Accuracy 0.9325 AUC 0.5194\n","Epoch 2 Batch 1830 Loss 0.0241 Accuracy 0.9324 AUC 0.5192\n","Epoch 2 Batch 1840 Loss 0.0241 Accuracy 0.9325 AUC 0.5188\n","Epoch 2 Batch 1850 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 1860 Loss 0.0241 Accuracy 0.9325 AUC 0.5186\n","Epoch 2 Batch 1870 Loss 0.0241 Accuracy 0.9325 AUC 0.5185\n","Epoch 2 Batch 1880 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 1890 Loss 0.0241 Accuracy 0.9324 AUC 0.5185\n","Epoch 2 Batch 1900 Loss 0.0241 Accuracy 0.9324 AUC 0.5186\n","Epoch 2 Batch 1910 Loss 0.0241 Accuracy 0.9324 AUC 0.5185\n","Epoch 2 Batch 1920 Loss 0.0241 Accuracy 0.9324 AUC 0.5183\n","Epoch 2 Batch 1930 Loss 0.0241 Accuracy 0.9324 AUC 0.5180\n","Epoch 2 Batch 1940 Loss 0.0241 Accuracy 0.9324 AUC 0.5177\n","Epoch 2 Batch 1950 Loss 0.0241 Accuracy 0.9325 AUC 0.5180\n","Epoch 2 Batch 1960 Loss 0.0241 Accuracy 0.9325 AUC 0.5179\n","Epoch 2 Batch 1970 Loss 0.0241 Accuracy 0.9325 AUC 0.5180\n","Epoch 2 Batch 1980 Loss 0.0241 Accuracy 0.9325 AUC 0.5182\n","Epoch 2 Batch 1990 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 2000 Loss 0.0241 Accuracy 0.9325 AUC 0.5188\n","Epoch 2 Batch 2010 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 2020 Loss 0.0241 Accuracy 0.9326 AUC 0.5187\n","Epoch 2 Batch 2030 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 2040 Loss 0.0241 Accuracy 0.9325 AUC 0.5188\n","Epoch 2 Batch 2050 Loss 0.0241 Accuracy 0.9324 AUC 0.5191\n","Epoch 2 Batch 2060 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 2070 Loss 0.0241 Accuracy 0.9325 AUC 0.5187\n","Epoch 2 Batch 2080 Loss 0.0241 Accuracy 0.9324 AUC 0.5189\n","Epoch 2 Batch 2090 Loss 0.0241 Accuracy 0.9325 AUC 0.5189\n","Epoch 2 Batch 2100 Loss 0.0241 Accuracy 0.9325 AUC 0.5190\n","Epoch 2 Loss 0.0241 Accuracy 0.9325\n","Time taken for 1 epoch: 713.7340245246887 secs\n","\n","Epoch 3 Batch 0 Loss 0.0180 Accuracy 0.9531 AUC 0.6066\n","Epoch 3 Batch 10 Loss 0.0232 Accuracy 0.9332 AUC 0.5760\n","Epoch 3 Batch 20 Loss 0.0253 Accuracy 0.9256 AUC 0.5538\n","Epoch 3 Batch 30 Loss 0.0238 Accuracy 0.9325 AUC 0.5419\n","Epoch 3 Batch 40 Loss 0.0245 Accuracy 0.9303 AUC 0.5259\n","Epoch 3 Batch 50 Loss 0.0243 Accuracy 0.9314 AUC 0.5206\n","Epoch 3 Batch 60 Loss 0.0248 Accuracy 0.9293 AUC 0.5277\n","Epoch 3 Batch 70 Loss 0.0246 Accuracy 0.9298 AUC 0.5285\n","Epoch 3 Batch 80 Loss 0.0248 Accuracy 0.9290 AUC 0.5260\n","Epoch 3 Batch 90 Loss 0.0247 Accuracy 0.9296 AUC 0.5256\n","Epoch 3 Batch 100 Loss 0.0247 Accuracy 0.9299 AUC 0.5217\n","Epoch 3 Batch 110 Loss 0.0249 Accuracy 0.9293 AUC 0.5148\n","Epoch 3 Batch 120 Loss 0.0247 Accuracy 0.9301 AUC 0.5125\n","Epoch 3 Batch 130 Loss 0.0246 Accuracy 0.9302 AUC 0.5117\n","Epoch 3 Batch 140 Loss 0.0245 Accuracy 0.9305 AUC 0.5135\n","Epoch 3 Batch 150 Loss 0.0245 Accuracy 0.9308 AUC 0.5119\n","Epoch 3 Batch 160 Loss 0.0246 Accuracy 0.9303 AUC 0.5128\n","Epoch 3 Batch 170 Loss 0.0247 Accuracy 0.9301 AUC 0.5110\n","Epoch 3 Batch 180 Loss 0.0246 Accuracy 0.9302 AUC 0.5101\n","Epoch 3 Batch 190 Loss 0.0245 Accuracy 0.9305 AUC 0.5107\n","Epoch 3 Batch 200 Loss 0.0246 Accuracy 0.9301 AUC 0.5137\n","Epoch 3 Batch 210 Loss 0.0244 Accuracy 0.9310 AUC 0.5144\n","Epoch 3 Batch 220 Loss 0.0243 Accuracy 0.9314 AUC 0.5109\n","Epoch 3 Batch 230 Loss 0.0240 Accuracy 0.9323 AUC 0.5151\n","Epoch 3 Batch 240 Loss 0.0240 Accuracy 0.9326 AUC 0.5173\n","Epoch 3 Batch 250 Loss 0.0241 Accuracy 0.9323 AUC 0.5176\n","Epoch 3 Batch 260 Loss 0.0240 Accuracy 0.9324 AUC 0.5218\n","Epoch 3 Batch 270 Loss 0.0240 Accuracy 0.9325 AUC 0.5184\n","Epoch 3 Batch 280 Loss 0.0238 Accuracy 0.9332 AUC 0.5195\n","Epoch 3 Batch 290 Loss 0.0238 Accuracy 0.9332 AUC 0.5210\n","Epoch 3 Batch 300 Loss 0.0237 Accuracy 0.9335 AUC 0.5209\n","Epoch 3 Batch 310 Loss 0.0238 Accuracy 0.9332 AUC 0.5190\n","Epoch 3 Batch 320 Loss 0.0238 Accuracy 0.9330 AUC 0.5197\n","Epoch 3 Batch 330 Loss 0.0238 Accuracy 0.9330 AUC 0.5196\n","Epoch 3 Batch 340 Loss 0.0238 Accuracy 0.9331 AUC 0.5198\n","Epoch 3 Batch 350 Loss 0.0238 Accuracy 0.9331 AUC 0.5196\n","Epoch 3 Batch 360 Loss 0.0239 Accuracy 0.9329 AUC 0.5194\n","Epoch 3 Batch 370 Loss 0.0239 Accuracy 0.9325 AUC 0.5195\n","Epoch 3 Batch 380 Loss 0.0239 Accuracy 0.9328 AUC 0.5202\n","Epoch 3 Batch 390 Loss 0.0239 Accuracy 0.9326 AUC 0.5196\n","Epoch 3 Batch 400 Loss 0.0239 Accuracy 0.9326 AUC 0.5190\n","Epoch 3 Batch 410 Loss 0.0239 Accuracy 0.9327 AUC 0.5200\n","Epoch 3 Batch 420 Loss 0.0238 Accuracy 0.9329 AUC 0.5208\n","Epoch 3 Batch 430 Loss 0.0237 Accuracy 0.9331 AUC 0.5237\n","Epoch 3 Batch 440 Loss 0.0237 Accuracy 0.9332 AUC 0.5251\n","Epoch 3 Batch 450 Loss 0.0238 Accuracy 0.9330 AUC 0.5271\n","Epoch 3 Batch 460 Loss 0.0238 Accuracy 0.9330 AUC 0.5273\n","Epoch 3 Batch 470 Loss 0.0238 Accuracy 0.9328 AUC 0.5267\n","Epoch 3 Batch 480 Loss 0.0238 Accuracy 0.9328 AUC 0.5277\n","Epoch 3 Batch 490 Loss 0.0238 Accuracy 0.9330 AUC 0.5267\n","Epoch 3 Batch 500 Loss 0.0238 Accuracy 0.9329 AUC 0.5248\n","Epoch 3 Batch 510 Loss 0.0238 Accuracy 0.9330 AUC 0.5260\n","Epoch 3 Batch 520 Loss 0.0239 Accuracy 0.9326 AUC 0.5258\n","Epoch 3 Batch 530 Loss 0.0238 Accuracy 0.9327 AUC 0.5259\n","Epoch 3 Batch 540 Loss 0.0239 Accuracy 0.9327 AUC 0.5258\n","Epoch 3 Batch 550 Loss 0.0238 Accuracy 0.9328 AUC 0.5263\n","Epoch 3 Batch 560 Loss 0.0238 Accuracy 0.9327 AUC 0.5273\n","Epoch 3 Batch 570 Loss 0.0239 Accuracy 0.9327 AUC 0.5272\n","Epoch 3 Batch 580 Loss 0.0238 Accuracy 0.9328 AUC 0.5267\n","Epoch 3 Batch 590 Loss 0.0239 Accuracy 0.9326 AUC 0.5271\n","Epoch 3 Batch 600 Loss 0.0239 Accuracy 0.9325 AUC 0.5272\n","Epoch 3 Batch 610 Loss 0.0239 Accuracy 0.9325 AUC 0.5269\n","Epoch 3 Batch 620 Loss 0.0239 Accuracy 0.9325 AUC 0.5268\n","Epoch 3 Batch 630 Loss 0.0239 Accuracy 0.9326 AUC 0.5260\n","Epoch 3 Batch 640 Loss 0.0240 Accuracy 0.9323 AUC 0.5257\n","Epoch 3 Batch 650 Loss 0.0239 Accuracy 0.9325 AUC 0.5258\n","Epoch 3 Batch 660 Loss 0.0239 Accuracy 0.9325 AUC 0.5251\n","Epoch 3 Batch 670 Loss 0.0240 Accuracy 0.9323 AUC 0.5247\n","Epoch 3 Batch 680 Loss 0.0240 Accuracy 0.9320 AUC 0.5250\n","Epoch 3 Batch 690 Loss 0.0241 Accuracy 0.9317 AUC 0.5258\n","Epoch 3 Batch 700 Loss 0.0241 Accuracy 0.9317 AUC 0.5262\n","Epoch 3 Batch 710 Loss 0.0241 Accuracy 0.9318 AUC 0.5263\n","Epoch 3 Batch 720 Loss 0.0241 Accuracy 0.9319 AUC 0.5263\n","Epoch 3 Batch 730 Loss 0.0240 Accuracy 0.9322 AUC 0.5275\n","Epoch 3 Batch 740 Loss 0.0240 Accuracy 0.9320 AUC 0.5281\n","Epoch 3 Batch 750 Loss 0.0241 Accuracy 0.9318 AUC 0.5284\n","Epoch 3 Batch 760 Loss 0.0241 Accuracy 0.9316 AUC 0.5284\n","Epoch 3 Batch 770 Loss 0.0241 Accuracy 0.9316 AUC 0.5282\n","Epoch 3 Batch 780 Loss 0.0241 Accuracy 0.9316 AUC 0.5285\n","Epoch 3 Batch 790 Loss 0.0241 Accuracy 0.9318 AUC 0.5294\n","Epoch 3 Batch 800 Loss 0.0240 Accuracy 0.9319 AUC 0.5299\n","Epoch 3 Batch 810 Loss 0.0240 Accuracy 0.9319 AUC 0.5305\n","Epoch 3 Batch 820 Loss 0.0240 Accuracy 0.9318 AUC 0.5312\n","Epoch 3 Batch 830 Loss 0.0240 Accuracy 0.9320 AUC 0.5313\n","Epoch 3 Batch 840 Loss 0.0240 Accuracy 0.9320 AUC 0.5322\n","Epoch 3 Batch 850 Loss 0.0240 Accuracy 0.9319 AUC 0.5321\n","Epoch 3 Batch 860 Loss 0.0240 Accuracy 0.9319 AUC 0.5316\n","Epoch 3 Batch 870 Loss 0.0240 Accuracy 0.9320 AUC 0.5319\n","Epoch 3 Batch 880 Loss 0.0241 Accuracy 0.9318 AUC 0.5323\n","Epoch 3 Batch 890 Loss 0.0240 Accuracy 0.9318 AUC 0.5320\n","Epoch 3 Batch 900 Loss 0.0240 Accuracy 0.9320 AUC 0.5322\n","Epoch 3 Batch 910 Loss 0.0240 Accuracy 0.9320 AUC 0.5322\n","Epoch 3 Batch 920 Loss 0.0240 Accuracy 0.9321 AUC 0.5326\n","Epoch 3 Batch 930 Loss 0.0240 Accuracy 0.9321 AUC 0.5325\n","Epoch 3 Batch 940 Loss 0.0240 Accuracy 0.9321 AUC 0.5320\n","Epoch 3 Batch 950 Loss 0.0240 Accuracy 0.9321 AUC 0.5322\n","Epoch 3 Batch 960 Loss 0.0240 Accuracy 0.9319 AUC 0.5324\n","Epoch 3 Batch 970 Loss 0.0240 Accuracy 0.9320 AUC 0.5320\n","Epoch 3 Batch 980 Loss 0.0240 Accuracy 0.9321 AUC 0.5317\n","Epoch 3 Batch 990 Loss 0.0240 Accuracy 0.9321 AUC 0.5320\n","Epoch 3 Batch 1000 Loss 0.0240 Accuracy 0.9321 AUC 0.5323\n","Epoch 3 Batch 1010 Loss 0.0240 Accuracy 0.9319 AUC 0.5332\n","Epoch 3 Batch 1020 Loss 0.0240 Accuracy 0.9318 AUC 0.5338\n","Epoch 3 Batch 1030 Loss 0.0240 Accuracy 0.9319 AUC 0.5343\n","Epoch 3 Batch 1040 Loss 0.0240 Accuracy 0.9318 AUC 0.5344\n","Epoch 3 Batch 1050 Loss 0.0240 Accuracy 0.9318 AUC 0.5343\n","Epoch 3 Batch 1060 Loss 0.0240 Accuracy 0.9318 AUC 0.5339\n","Epoch 3 Batch 1070 Loss 0.0240 Accuracy 0.9318 AUC 0.5338\n","Epoch 3 Batch 1080 Loss 0.0240 Accuracy 0.9318 AUC 0.5338\n","Epoch 3 Batch 1090 Loss 0.0240 Accuracy 0.9319 AUC 0.5332\n","Epoch 3 Batch 1100 Loss 0.0240 Accuracy 0.9320 AUC 0.5330\n","Epoch 3 Batch 1110 Loss 0.0240 Accuracy 0.9319 AUC 0.5329\n","Epoch 3 Batch 1120 Loss 0.0239 Accuracy 0.9321 AUC 0.5340\n","Epoch 3 Batch 1130 Loss 0.0239 Accuracy 0.9323 AUC 0.5352\n","Epoch 3 Batch 1140 Loss 0.0239 Accuracy 0.9323 AUC 0.5361\n","Epoch 3 Batch 1150 Loss 0.0238 Accuracy 0.9325 AUC 0.5364\n","Epoch 3 Batch 1160 Loss 0.0239 Accuracy 0.9323 AUC 0.5364\n","Epoch 3 Batch 1170 Loss 0.0239 Accuracy 0.9322 AUC 0.5369\n","Epoch 3 Batch 1180 Loss 0.0239 Accuracy 0.9321 AUC 0.5371\n","Epoch 3 Batch 1190 Loss 0.0239 Accuracy 0.9322 AUC 0.5368\n","Epoch 3 Batch 1200 Loss 0.0239 Accuracy 0.9320 AUC 0.5372\n","Epoch 3 Batch 1210 Loss 0.0240 Accuracy 0.9320 AUC 0.5369\n","Epoch 3 Batch 1220 Loss 0.0239 Accuracy 0.9320 AUC 0.5368\n","Epoch 3 Batch 1230 Loss 0.0239 Accuracy 0.9321 AUC 0.5369\n","Epoch 3 Batch 1240 Loss 0.0239 Accuracy 0.9321 AUC 0.5365\n","Epoch 3 Batch 1250 Loss 0.0239 Accuracy 0.9322 AUC 0.5365\n","Epoch 3 Batch 1260 Loss 0.0239 Accuracy 0.9322 AUC 0.5371\n","Epoch 3 Batch 1270 Loss 0.0239 Accuracy 0.9324 AUC 0.5370\n","Epoch 3 Batch 1280 Loss 0.0239 Accuracy 0.9324 AUC 0.5365\n","Epoch 3 Batch 1290 Loss 0.0239 Accuracy 0.9324 AUC 0.5368\n","Epoch 3 Batch 1300 Loss 0.0238 Accuracy 0.9324 AUC 0.5365\n","Epoch 3 Batch 1310 Loss 0.0238 Accuracy 0.9324 AUC 0.5362\n","Epoch 3 Batch 1320 Loss 0.0238 Accuracy 0.9325 AUC 0.5363\n","Epoch 3 Batch 1330 Loss 0.0239 Accuracy 0.9324 AUC 0.5360\n","Epoch 3 Batch 1340 Loss 0.0239 Accuracy 0.9323 AUC 0.5367\n","Epoch 3 Batch 1350 Loss 0.0239 Accuracy 0.9322 AUC 0.5365\n","Epoch 3 Batch 1360 Loss 0.0239 Accuracy 0.9322 AUC 0.5364\n","Epoch 3 Batch 1370 Loss 0.0239 Accuracy 0.9323 AUC 0.5366\n","Epoch 3 Batch 1380 Loss 0.0239 Accuracy 0.9323 AUC 0.5366\n","Epoch 3 Batch 1390 Loss 0.0238 Accuracy 0.9324 AUC 0.5366\n","Epoch 3 Batch 1400 Loss 0.0238 Accuracy 0.9325 AUC 0.5366\n","Epoch 3 Batch 1410 Loss 0.0238 Accuracy 0.9324 AUC 0.5371\n","Epoch 3 Batch 1420 Loss 0.0238 Accuracy 0.9326 AUC 0.5371\n","Epoch 3 Batch 1430 Loss 0.0238 Accuracy 0.9325 AUC 0.5368\n","Epoch 3 Batch 1440 Loss 0.0238 Accuracy 0.9324 AUC 0.5369\n","Epoch 3 Batch 1450 Loss 0.0238 Accuracy 0.9324 AUC 0.5370\n","Epoch 3 Batch 1460 Loss 0.0238 Accuracy 0.9326 AUC 0.5373\n","Epoch 3 Batch 1470 Loss 0.0238 Accuracy 0.9326 AUC 0.5372\n","Epoch 3 Batch 1480 Loss 0.0238 Accuracy 0.9327 AUC 0.5369\n","Epoch 3 Batch 1490 Loss 0.0238 Accuracy 0.9325 AUC 0.5370\n","Epoch 3 Batch 1500 Loss 0.0238 Accuracy 0.9326 AUC 0.5373\n","Epoch 3 Batch 1510 Loss 0.0238 Accuracy 0.9326 AUC 0.5368\n","Epoch 3 Batch 1520 Loss 0.0238 Accuracy 0.9327 AUC 0.5367\n","Epoch 3 Batch 1530 Loss 0.0238 Accuracy 0.9326 AUC 0.5369\n","Epoch 3 Batch 1540 Loss 0.0238 Accuracy 0.9325 AUC 0.5372\n","Epoch 3 Batch 1550 Loss 0.0238 Accuracy 0.9324 AUC 0.5377\n","Epoch 3 Batch 1560 Loss 0.0238 Accuracy 0.9324 AUC 0.5377\n","Epoch 3 Batch 1570 Loss 0.0238 Accuracy 0.9324 AUC 0.5372\n","Epoch 3 Batch 1580 Loss 0.0238 Accuracy 0.9324 AUC 0.5373\n","Epoch 3 Batch 1590 Loss 0.0238 Accuracy 0.9325 AUC 0.5374\n","Epoch 3 Batch 1600 Loss 0.0238 Accuracy 0.9325 AUC 0.5375\n","Epoch 3 Batch 1610 Loss 0.0238 Accuracy 0.9325 AUC 0.5374\n","Epoch 3 Batch 1620 Loss 0.0238 Accuracy 0.9325 AUC 0.5374\n","Epoch 3 Batch 1630 Loss 0.0238 Accuracy 0.9324 AUC 0.5374\n","Epoch 3 Batch 1640 Loss 0.0238 Accuracy 0.9325 AUC 0.5379\n","Epoch 3 Batch 1650 Loss 0.0238 Accuracy 0.9326 AUC 0.5387\n","Epoch 3 Batch 1660 Loss 0.0238 Accuracy 0.9326 AUC 0.5389\n","Epoch 3 Batch 1670 Loss 0.0238 Accuracy 0.9326 AUC 0.5390\n","Epoch 3 Batch 1680 Loss 0.0238 Accuracy 0.9326 AUC 0.5387\n","Epoch 3 Batch 1690 Loss 0.0238 Accuracy 0.9325 AUC 0.5389\n","Epoch 3 Batch 1700 Loss 0.0238 Accuracy 0.9325 AUC 0.5390\n","Epoch 3 Batch 1710 Loss 0.0238 Accuracy 0.9324 AUC 0.5387\n","Epoch 3 Batch 1720 Loss 0.0238 Accuracy 0.9324 AUC 0.5386\n","Epoch 3 Batch 1730 Loss 0.0238 Accuracy 0.9324 AUC 0.5385\n","Epoch 3 Batch 1740 Loss 0.0238 Accuracy 0.9324 AUC 0.5384\n","Epoch 3 Batch 1750 Loss 0.0238 Accuracy 0.9324 AUC 0.5385\n","Epoch 3 Batch 1760 Loss 0.0238 Accuracy 0.9324 AUC 0.5382\n","Epoch 3 Batch 1770 Loss 0.0238 Accuracy 0.9323 AUC 0.5382\n","Epoch 3 Batch 1780 Loss 0.0238 Accuracy 0.9324 AUC 0.5383\n","Epoch 3 Batch 1790 Loss 0.0238 Accuracy 0.9325 AUC 0.5382\n","Epoch 3 Batch 1800 Loss 0.0238 Accuracy 0.9325 AUC 0.5384\n","Epoch 3 Batch 1810 Loss 0.0238 Accuracy 0.9325 AUC 0.5383\n","Epoch 3 Batch 1820 Loss 0.0238 Accuracy 0.9325 AUC 0.5383\n","Epoch 3 Batch 1830 Loss 0.0238 Accuracy 0.9324 AUC 0.5383\n","Epoch 3 Batch 1840 Loss 0.0238 Accuracy 0.9325 AUC 0.5382\n","Epoch 3 Batch 1850 Loss 0.0238 Accuracy 0.9325 AUC 0.5379\n","Epoch 3 Batch 1860 Loss 0.0238 Accuracy 0.9325 AUC 0.5381\n","Epoch 3 Batch 1870 Loss 0.0238 Accuracy 0.9325 AUC 0.5382\n","Epoch 3 Batch 1880 Loss 0.0238 Accuracy 0.9325 AUC 0.5383\n","Epoch 3 Batch 1890 Loss 0.0238 Accuracy 0.9324 AUC 0.5382\n","Epoch 3 Batch 1900 Loss 0.0238 Accuracy 0.9324 AUC 0.5379\n","Epoch 3 Batch 1910 Loss 0.0238 Accuracy 0.9324 AUC 0.5376\n","Epoch 3 Batch 1920 Loss 0.0238 Accuracy 0.9324 AUC 0.5375\n","Epoch 3 Batch 1930 Loss 0.0238 Accuracy 0.9324 AUC 0.5375\n","Epoch 3 Batch 1940 Loss 0.0238 Accuracy 0.9324 AUC 0.5375\n","Epoch 3 Batch 1950 Loss 0.0238 Accuracy 0.9325 AUC 0.5379\n","Epoch 3 Batch 1960 Loss 0.0238 Accuracy 0.9325 AUC 0.5374\n","Epoch 3 Batch 1970 Loss 0.0238 Accuracy 0.9325 AUC 0.5373\n","Epoch 3 Batch 1980 Loss 0.0238 Accuracy 0.9325 AUC 0.5376\n","Epoch 3 Batch 1990 Loss 0.0238 Accuracy 0.9325 AUC 0.5379\n","Epoch 3 Batch 2000 Loss 0.0238 Accuracy 0.9325 AUC 0.5381\n","Epoch 3 Batch 2010 Loss 0.0238 Accuracy 0.9325 AUC 0.5380\n","Epoch 3 Batch 2020 Loss 0.0238 Accuracy 0.9326 AUC 0.5380\n","Epoch 3 Batch 2030 Loss 0.0238 Accuracy 0.9325 AUC 0.5381\n","Epoch 3 Batch 2040 Loss 0.0238 Accuracy 0.9325 AUC 0.5382\n","Epoch 3 Batch 2050 Loss 0.0238 Accuracy 0.9324 AUC 0.5385\n","Epoch 3 Batch 2060 Loss 0.0238 Accuracy 0.9325 AUC 0.5384\n","Epoch 3 Batch 2070 Loss 0.0238 Accuracy 0.9325 AUC 0.5383\n","Epoch 3 Batch 2080 Loss 0.0238 Accuracy 0.9324 AUC 0.5383\n","Epoch 3 Batch 2090 Loss 0.0238 Accuracy 0.9325 AUC 0.5384\n","Epoch 3 Batch 2100 Loss 0.0238 Accuracy 0.9325 AUC 0.5384\n","Epoch 3 Loss 0.0238 Accuracy 0.9325\n","Time taken for 1 epoch: 714.650985956192 secs\n","\n","Epoch 4 Batch 0 Loss 0.0184 Accuracy 0.9531 AUC 0.5820\n","Epoch 4 Batch 10 Loss 0.0238 Accuracy 0.9332 AUC 0.4822\n","Epoch 4 Batch 20 Loss 0.0255 Accuracy 0.9256 AUC 0.5294\n","Epoch 4 Batch 30 Loss 0.0238 Accuracy 0.9325 AUC 0.5327\n","Epoch 4 Batch 40 Loss 0.0244 Accuracy 0.9303 AUC 0.5280\n","Epoch 4 Batch 50 Loss 0.0241 Accuracy 0.9314 AUC 0.5293\n","Epoch 4 Batch 60 Loss 0.0246 Accuracy 0.9293 AUC 0.5444\n","Epoch 4 Batch 70 Loss 0.0244 Accuracy 0.9298 AUC 0.5464\n","Epoch 4 Batch 80 Loss 0.0246 Accuracy 0.9290 AUC 0.5439\n","Epoch 4 Batch 90 Loss 0.0244 Accuracy 0.9296 AUC 0.5463\n","Epoch 4 Batch 100 Loss 0.0244 Accuracy 0.9299 AUC 0.5443\n","Epoch 4 Batch 110 Loss 0.0246 Accuracy 0.9293 AUC 0.5365\n","Epoch 4 Batch 120 Loss 0.0244 Accuracy 0.9301 AUC 0.5346\n","Epoch 4 Batch 130 Loss 0.0244 Accuracy 0.9302 AUC 0.5340\n","Epoch 4 Batch 140 Loss 0.0243 Accuracy 0.9305 AUC 0.5321\n","Epoch 4 Batch 150 Loss 0.0243 Accuracy 0.9308 AUC 0.5270\n","Epoch 4 Batch 160 Loss 0.0244 Accuracy 0.9303 AUC 0.5279\n","Epoch 4 Batch 170 Loss 0.0244 Accuracy 0.9301 AUC 0.5252\n","Epoch 4 Batch 180 Loss 0.0244 Accuracy 0.9302 AUC 0.5269\n","Epoch 4 Batch 190 Loss 0.0243 Accuracy 0.9305 AUC 0.5259\n","Epoch 4 Batch 200 Loss 0.0244 Accuracy 0.9301 AUC 0.5276\n","Epoch 4 Batch 210 Loss 0.0242 Accuracy 0.9310 AUC 0.5301\n","Epoch 4 Batch 220 Loss 0.0241 Accuracy 0.9314 AUC 0.5266\n","Epoch 4 Batch 230 Loss 0.0239 Accuracy 0.9323 AUC 0.5303\n","Epoch 4 Batch 240 Loss 0.0238 Accuracy 0.9326 AUC 0.5316\n","Epoch 4 Batch 250 Loss 0.0239 Accuracy 0.9323 AUC 0.5301\n","Epoch 4 Batch 260 Loss 0.0238 Accuracy 0.9324 AUC 0.5323\n","Epoch 4 Batch 270 Loss 0.0239 Accuracy 0.9325 AUC 0.5253\n","Epoch 4 Batch 280 Loss 0.0237 Accuracy 0.9332 AUC 0.5277\n","Epoch 4 Batch 290 Loss 0.0237 Accuracy 0.9332 AUC 0.5276\n","Epoch 4 Batch 300 Loss 0.0236 Accuracy 0.9335 AUC 0.5278\n","Epoch 4 Batch 310 Loss 0.0237 Accuracy 0.9332 AUC 0.5254\n","Epoch 4 Batch 320 Loss 0.0237 Accuracy 0.9330 AUC 0.5254\n","Epoch 4 Batch 330 Loss 0.0237 Accuracy 0.9330 AUC 0.5254\n","Epoch 4 Batch 340 Loss 0.0237 Accuracy 0.9331 AUC 0.5264\n","Epoch 4 Batch 350 Loss 0.0237 Accuracy 0.9331 AUC 0.5249\n","Epoch 4 Batch 360 Loss 0.0238 Accuracy 0.9329 AUC 0.5233\n","Epoch 4 Batch 370 Loss 0.0238 Accuracy 0.9325 AUC 0.5249\n","Epoch 4 Batch 380 Loss 0.0238 Accuracy 0.9328 AUC 0.5260\n","Epoch 4 Batch 390 Loss 0.0238 Accuracy 0.9326 AUC 0.5258\n","Epoch 4 Batch 400 Loss 0.0238 Accuracy 0.9326 AUC 0.5253\n","Epoch 4 Batch 410 Loss 0.0238 Accuracy 0.9327 AUC 0.5277\n","Epoch 4 Batch 420 Loss 0.0237 Accuracy 0.9329 AUC 0.5282\n","Epoch 4 Batch 430 Loss 0.0236 Accuracy 0.9331 AUC 0.5310\n","Epoch 4 Batch 440 Loss 0.0236 Accuracy 0.9332 AUC 0.5329\n","Epoch 4 Batch 450 Loss 0.0237 Accuracy 0.9330 AUC 0.5338\n","Epoch 4 Batch 460 Loss 0.0237 Accuracy 0.9330 AUC 0.5337\n","Epoch 4 Batch 470 Loss 0.0237 Accuracy 0.9328 AUC 0.5336\n","Epoch 4 Batch 480 Loss 0.0237 Accuracy 0.9328 AUC 0.5339\n","Epoch 4 Batch 490 Loss 0.0237 Accuracy 0.9330 AUC 0.5339\n","Epoch 4 Batch 500 Loss 0.0237 Accuracy 0.9329 AUC 0.5334\n","Epoch 4 Batch 510 Loss 0.0236 Accuracy 0.9330 AUC 0.5342\n","Epoch 4 Batch 520 Loss 0.0238 Accuracy 0.9326 AUC 0.5338\n","Epoch 4 Batch 530 Loss 0.0237 Accuracy 0.9327 AUC 0.5330\n","Epoch 4 Batch 540 Loss 0.0238 Accuracy 0.9327 AUC 0.5328\n","Epoch 4 Batch 550 Loss 0.0237 Accuracy 0.9328 AUC 0.5331\n","Epoch 4 Batch 560 Loss 0.0237 Accuracy 0.9327 AUC 0.5336\n","Epoch 4 Batch 570 Loss 0.0238 Accuracy 0.9327 AUC 0.5336\n","Epoch 4 Batch 580 Loss 0.0237 Accuracy 0.9328 AUC 0.5336\n","Epoch 4 Batch 590 Loss 0.0238 Accuracy 0.9326 AUC 0.5329\n","Epoch 4 Batch 600 Loss 0.0238 Accuracy 0.9325 AUC 0.5326\n","Epoch 4 Batch 610 Loss 0.0238 Accuracy 0.9325 AUC 0.5323\n","Epoch 4 Batch 620 Loss 0.0238 Accuracy 0.9325 AUC 0.5326\n","Epoch 4 Batch 630 Loss 0.0238 Accuracy 0.9326 AUC 0.5313\n","Epoch 4 Batch 640 Loss 0.0238 Accuracy 0.9323 AUC 0.5316\n","Epoch 4 Batch 650 Loss 0.0238 Accuracy 0.9325 AUC 0.5317\n","Epoch 4 Batch 660 Loss 0.0238 Accuracy 0.9325 AUC 0.5314\n","Epoch 4 Batch 670 Loss 0.0238 Accuracy 0.9323 AUC 0.5322\n","Epoch 4 Batch 680 Loss 0.0239 Accuracy 0.9320 AUC 0.5319\n","Epoch 4 Batch 690 Loss 0.0240 Accuracy 0.9317 AUC 0.5328\n","Epoch 4 Batch 700 Loss 0.0240 Accuracy 0.9317 AUC 0.5330\n","Epoch 4 Batch 710 Loss 0.0240 Accuracy 0.9318 AUC 0.5333\n","Epoch 4 Batch 720 Loss 0.0239 Accuracy 0.9319 AUC 0.5336\n","Epoch 4 Batch 730 Loss 0.0239 Accuracy 0.9322 AUC 0.5347\n","Epoch 4 Batch 740 Loss 0.0239 Accuracy 0.9320 AUC 0.5353\n","Epoch 4 Batch 750 Loss 0.0239 Accuracy 0.9318 AUC 0.5360\n","Epoch 4 Batch 760 Loss 0.0240 Accuracy 0.9316 AUC 0.5359\n","Epoch 4 Batch 770 Loss 0.0240 Accuracy 0.9316 AUC 0.5353\n","Epoch 4 Batch 780 Loss 0.0240 Accuracy 0.9316 AUC 0.5346\n","Epoch 4 Batch 790 Loss 0.0240 Accuracy 0.9318 AUC 0.5360\n","Epoch 4 Batch 800 Loss 0.0239 Accuracy 0.9319 AUC 0.5362\n","Epoch 4 Batch 810 Loss 0.0239 Accuracy 0.9319 AUC 0.5366\n","Epoch 4 Batch 820 Loss 0.0239 Accuracy 0.9318 AUC 0.5365\n","Epoch 4 Batch 830 Loss 0.0239 Accuracy 0.9320 AUC 0.5357\n","Epoch 4 Batch 840 Loss 0.0239 Accuracy 0.9320 AUC 0.5361\n","Epoch 4 Batch 850 Loss 0.0239 Accuracy 0.9319 AUC 0.5364\n","Epoch 4 Batch 860 Loss 0.0239 Accuracy 0.9319 AUC 0.5356\n","Epoch 4 Batch 870 Loss 0.0239 Accuracy 0.9320 AUC 0.5356\n","Epoch 4 Batch 880 Loss 0.0240 Accuracy 0.9318 AUC 0.5356\n","Epoch 4 Batch 890 Loss 0.0239 Accuracy 0.9318 AUC 0.5355\n","Epoch 4 Batch 900 Loss 0.0239 Accuracy 0.9320 AUC 0.5352\n","Epoch 4 Batch 910 Loss 0.0239 Accuracy 0.9320 AUC 0.5350\n","Epoch 4 Batch 920 Loss 0.0239 Accuracy 0.9321 AUC 0.5356\n","Epoch 4 Batch 930 Loss 0.0239 Accuracy 0.9321 AUC 0.5357\n","Epoch 4 Batch 940 Loss 0.0239 Accuracy 0.9321 AUC 0.5352\n","Epoch 4 Batch 950 Loss 0.0239 Accuracy 0.9321 AUC 0.5354\n","Epoch 4 Batch 960 Loss 0.0239 Accuracy 0.9319 AUC 0.5362\n","Epoch 4 Batch 970 Loss 0.0239 Accuracy 0.9320 AUC 0.5357\n","Epoch 4 Batch 980 Loss 0.0239 Accuracy 0.9321 AUC 0.5356\n","Epoch 4 Batch 990 Loss 0.0239 Accuracy 0.9321 AUC 0.5365\n","Epoch 4 Batch 1000 Loss 0.0239 Accuracy 0.9321 AUC 0.5367\n","Epoch 4 Batch 1010 Loss 0.0239 Accuracy 0.9319 AUC 0.5374\n","Epoch 4 Batch 1020 Loss 0.0239 Accuracy 0.9318 AUC 0.5375\n","Epoch 4 Batch 1030 Loss 0.0239 Accuracy 0.9319 AUC 0.5373\n","Epoch 4 Batch 1040 Loss 0.0239 Accuracy 0.9318 AUC 0.5376\n","Epoch 4 Batch 1050 Loss 0.0239 Accuracy 0.9318 AUC 0.5375\n","Epoch 4 Batch 1060 Loss 0.0239 Accuracy 0.9318 AUC 0.5368\n","Epoch 4 Batch 1070 Loss 0.0239 Accuracy 0.9318 AUC 0.5370\n","Epoch 4 Batch 1080 Loss 0.0239 Accuracy 0.9318 AUC 0.5369\n","Epoch 4 Batch 1090 Loss 0.0239 Accuracy 0.9319 AUC 0.5361\n","Epoch 4 Batch 1100 Loss 0.0239 Accuracy 0.9320 AUC 0.5359\n","Epoch 4 Batch 1110 Loss 0.0239 Accuracy 0.9319 AUC 0.5362\n","Epoch 4 Batch 1120 Loss 0.0238 Accuracy 0.9321 AUC 0.5374\n","Epoch 4 Batch 1130 Loss 0.0238 Accuracy 0.9323 AUC 0.5384\n","Epoch 4 Batch 1140 Loss 0.0238 Accuracy 0.9323 AUC 0.5386\n","Epoch 4 Batch 1150 Loss 0.0238 Accuracy 0.9325 AUC 0.5387\n","Epoch 4 Batch 1160 Loss 0.0238 Accuracy 0.9323 AUC 0.5387\n","Epoch 4 Batch 1170 Loss 0.0238 Accuracy 0.9322 AUC 0.5392\n","Epoch 4 Batch 1180 Loss 0.0238 Accuracy 0.9321 AUC 0.5394\n","Epoch 4 Batch 1190 Loss 0.0238 Accuracy 0.9322 AUC 0.5390\n","Epoch 4 Batch 1200 Loss 0.0238 Accuracy 0.9320 AUC 0.5394\n","Epoch 4 Batch 1210 Loss 0.0239 Accuracy 0.9320 AUC 0.5393\n","Epoch 4 Batch 1220 Loss 0.0239 Accuracy 0.9320 AUC 0.5393\n","Epoch 4 Batch 1230 Loss 0.0238 Accuracy 0.9321 AUC 0.5392\n","Epoch 4 Batch 1240 Loss 0.0238 Accuracy 0.9321 AUC 0.5386\n","Epoch 4 Batch 1250 Loss 0.0238 Accuracy 0.9322 AUC 0.5382\n","Epoch 4 Batch 1260 Loss 0.0238 Accuracy 0.9322 AUC 0.5386\n","Epoch 4 Batch 1270 Loss 0.0238 Accuracy 0.9324 AUC 0.5385\n","Epoch 4 Batch 1280 Loss 0.0238 Accuracy 0.9324 AUC 0.5380\n","Epoch 4 Batch 1290 Loss 0.0238 Accuracy 0.9324 AUC 0.5379\n","Epoch 4 Batch 1300 Loss 0.0238 Accuracy 0.9324 AUC 0.5377\n","Epoch 4 Batch 1310 Loss 0.0238 Accuracy 0.9324 AUC 0.5375\n","Epoch 4 Batch 1320 Loss 0.0238 Accuracy 0.9325 AUC 0.5375\n","Epoch 4 Batch 1330 Loss 0.0238 Accuracy 0.9324 AUC 0.5375\n","Epoch 4 Batch 1340 Loss 0.0238 Accuracy 0.9323 AUC 0.5381\n","Epoch 4 Batch 1350 Loss 0.0238 Accuracy 0.9322 AUC 0.5381\n","Epoch 4 Batch 1360 Loss 0.0238 Accuracy 0.9322 AUC 0.5379\n","Epoch 4 Batch 1370 Loss 0.0238 Accuracy 0.9323 AUC 0.5381\n","Epoch 4 Batch 1380 Loss 0.0238 Accuracy 0.9323 AUC 0.5384\n","Epoch 4 Batch 1390 Loss 0.0238 Accuracy 0.9324 AUC 0.5386\n","Epoch 4 Batch 1400 Loss 0.0237 Accuracy 0.9325 AUC 0.5387\n","Epoch 4 Batch 1410 Loss 0.0238 Accuracy 0.9324 AUC 0.5390\n","Epoch 4 Batch 1420 Loss 0.0237 Accuracy 0.9326 AUC 0.5387\n","Epoch 4 Batch 1430 Loss 0.0237 Accuracy 0.9325 AUC 0.5384\n","Epoch 4 Batch 1440 Loss 0.0238 Accuracy 0.9324 AUC 0.5384\n","Epoch 4 Batch 1450 Loss 0.0238 Accuracy 0.9324 AUC 0.5390\n","Epoch 4 Batch 1460 Loss 0.0237 Accuracy 0.9326 AUC 0.5392\n","Epoch 4 Batch 1470 Loss 0.0237 Accuracy 0.9326 AUC 0.5390\n","Epoch 4 Batch 1480 Loss 0.0237 Accuracy 0.9327 AUC 0.5389\n","Epoch 4 Batch 1490 Loss 0.0237 Accuracy 0.9325 AUC 0.5389\n","Epoch 4 Batch 1500 Loss 0.0237 Accuracy 0.9326 AUC 0.5388\n","Epoch 4 Batch 1510 Loss 0.0237 Accuracy 0.9326 AUC 0.5384\n","Epoch 4 Batch 1520 Loss 0.0237 Accuracy 0.9327 AUC 0.5382\n","Epoch 4 Batch 1530 Loss 0.0237 Accuracy 0.9326 AUC 0.5385\n","Epoch 4 Batch 1540 Loss 0.0237 Accuracy 0.9325 AUC 0.5389\n","Epoch 4 Batch 1550 Loss 0.0238 Accuracy 0.9324 AUC 0.5392\n","Epoch 4 Batch 1560 Loss 0.0238 Accuracy 0.9324 AUC 0.5393\n","Epoch 4 Batch 1570 Loss 0.0238 Accuracy 0.9324 AUC 0.5391\n","Epoch 4 Batch 1580 Loss 0.0238 Accuracy 0.9324 AUC 0.5391\n","Epoch 4 Batch 1590 Loss 0.0237 Accuracy 0.9325 AUC 0.5393\n","Epoch 4 Batch 1600 Loss 0.0237 Accuracy 0.9325 AUC 0.5394\n","Epoch 4 Batch 1610 Loss 0.0237 Accuracy 0.9325 AUC 0.5394\n","Epoch 4 Batch 1620 Loss 0.0237 Accuracy 0.9325 AUC 0.5398\n","Epoch 4 Batch 1630 Loss 0.0237 Accuracy 0.9324 AUC 0.5401\n","Epoch 4 Batch 1640 Loss 0.0237 Accuracy 0.9325 AUC 0.5406\n","Epoch 4 Batch 1650 Loss 0.0237 Accuracy 0.9326 AUC 0.5416\n","Epoch 4 Batch 1660 Loss 0.0237 Accuracy 0.9326 AUC 0.5418\n","Epoch 4 Batch 1670 Loss 0.0237 Accuracy 0.9326 AUC 0.5419\n","Epoch 4 Batch 1680 Loss 0.0237 Accuracy 0.9326 AUC 0.5418\n","Epoch 4 Batch 1690 Loss 0.0237 Accuracy 0.9325 AUC 0.5420\n","Epoch 4 Batch 1700 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 1710 Loss 0.0237 Accuracy 0.9324 AUC 0.5420\n","Epoch 4 Batch 1720 Loss 0.0237 Accuracy 0.9324 AUC 0.5423\n","Epoch 4 Batch 1730 Loss 0.0237 Accuracy 0.9324 AUC 0.5421\n","Epoch 4 Batch 1740 Loss 0.0237 Accuracy 0.9324 AUC 0.5425\n","Epoch 4 Batch 1750 Loss 0.0237 Accuracy 0.9324 AUC 0.5423\n","Epoch 4 Batch 1760 Loss 0.0237 Accuracy 0.9324 AUC 0.5423\n","Epoch 4 Batch 1770 Loss 0.0237 Accuracy 0.9323 AUC 0.5423\n","Epoch 4 Batch 1780 Loss 0.0237 Accuracy 0.9324 AUC 0.5423\n","Epoch 4 Batch 1790 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 4 Batch 1800 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 4 Batch 1810 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 1820 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 4 Batch 1830 Loss 0.0237 Accuracy 0.9324 AUC 0.5424\n","Epoch 4 Batch 1840 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 4 Batch 1850 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 1860 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 1870 Loss 0.0237 Accuracy 0.9325 AUC 0.5425\n","Epoch 4 Batch 1880 Loss 0.0237 Accuracy 0.9325 AUC 0.5426\n","Epoch 4 Batch 1890 Loss 0.0237 Accuracy 0.9324 AUC 0.5423\n","Epoch 4 Batch 1900 Loss 0.0237 Accuracy 0.9324 AUC 0.5422\n","Epoch 4 Batch 1910 Loss 0.0237 Accuracy 0.9324 AUC 0.5420\n","Epoch 4 Batch 1920 Loss 0.0237 Accuracy 0.9324 AUC 0.5416\n","Epoch 4 Batch 1930 Loss 0.0237 Accuracy 0.9324 AUC 0.5416\n","Epoch 4 Batch 1940 Loss 0.0237 Accuracy 0.9324 AUC 0.5416\n","Epoch 4 Batch 1950 Loss 0.0237 Accuracy 0.9325 AUC 0.5419\n","Epoch 4 Batch 1960 Loss 0.0237 Accuracy 0.9325 AUC 0.5418\n","Epoch 4 Batch 1970 Loss 0.0237 Accuracy 0.9325 AUC 0.5420\n","Epoch 4 Batch 1980 Loss 0.0237 Accuracy 0.9325 AUC 0.5421\n","Epoch 4 Batch 1990 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 2000 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 4 Batch 2010 Loss 0.0237 Accuracy 0.9325 AUC 0.5422\n","Epoch 4 Batch 2020 Loss 0.0237 Accuracy 0.9326 AUC 0.5420\n","Epoch 4 Batch 2030 Loss 0.0237 Accuracy 0.9325 AUC 0.5421\n","Epoch 4 Batch 2040 Loss 0.0237 Accuracy 0.9325 AUC 0.5420\n","Epoch 4 Batch 2050 Loss 0.0237 Accuracy 0.9324 AUC 0.5421\n","Epoch 4 Batch 2060 Loss 0.0237 Accuracy 0.9325 AUC 0.5419\n","Epoch 4 Batch 2070 Loss 0.0237 Accuracy 0.9325 AUC 0.5419\n","Epoch 4 Batch 2080 Loss 0.0237 Accuracy 0.9324 AUC 0.5418\n","Epoch 4 Batch 2090 Loss 0.0237 Accuracy 0.9325 AUC 0.5419\n","Epoch 4 Batch 2100 Loss 0.0237 Accuracy 0.9325 AUC 0.5420\n","Epoch 4 Loss 0.0237 Accuracy 0.9325\n","Time taken for 1 epoch: 713.6748180389404 secs\n","\n","Epoch 5 Batch 0 Loss 0.0179 Accuracy 0.9531 AUC 0.6721\n","Epoch 5 Batch 10 Loss 0.0238 Accuracy 0.9332 AUC 0.4877\n","Epoch 5 Batch 20 Loss 0.0254 Accuracy 0.9256 AUC 0.5454\n","Epoch 5 Batch 30 Loss 0.0237 Accuracy 0.9325 AUC 0.5395\n","Epoch 5 Batch 40 Loss 0.0245 Accuracy 0.9303 AUC 0.5202\n","Epoch 5 Batch 50 Loss 0.0241 Accuracy 0.9314 AUC 0.5292\n","Epoch 5 Batch 60 Loss 0.0246 Accuracy 0.9293 AUC 0.5408\n","Epoch 5 Batch 70 Loss 0.0244 Accuracy 0.9298 AUC 0.5388\n","Epoch 5 Batch 80 Loss 0.0247 Accuracy 0.9290 AUC 0.5344\n","Epoch 5 Batch 90 Loss 0.0245 Accuracy 0.9296 AUC 0.5305\n","Epoch 5 Batch 100 Loss 0.0245 Accuracy 0.9299 AUC 0.5308\n","Epoch 5 Batch 110 Loss 0.0247 Accuracy 0.9293 AUC 0.5259\n","Epoch 5 Batch 120 Loss 0.0245 Accuracy 0.9301 AUC 0.5227\n","Epoch 5 Batch 130 Loss 0.0244 Accuracy 0.9302 AUC 0.5229\n","Epoch 5 Batch 140 Loss 0.0244 Accuracy 0.9305 AUC 0.5206\n","Epoch 5 Batch 150 Loss 0.0243 Accuracy 0.9308 AUC 0.5193\n","Epoch 5 Batch 160 Loss 0.0244 Accuracy 0.9303 AUC 0.5201\n","Epoch 5 Batch 170 Loss 0.0245 Accuracy 0.9301 AUC 0.5203\n","Epoch 5 Batch 180 Loss 0.0244 Accuracy 0.9302 AUC 0.5197\n","Epoch 5 Batch 190 Loss 0.0243 Accuracy 0.9305 AUC 0.5198\n","Epoch 5 Batch 200 Loss 0.0244 Accuracy 0.9301 AUC 0.5238\n","Epoch 5 Batch 210 Loss 0.0242 Accuracy 0.9310 AUC 0.5245\n","Epoch 5 Batch 220 Loss 0.0241 Accuracy 0.9314 AUC 0.5208\n","Epoch 5 Batch 230 Loss 0.0239 Accuracy 0.9323 AUC 0.5244\n","Epoch 5 Batch 240 Loss 0.0238 Accuracy 0.9326 AUC 0.5265\n","Epoch 5 Batch 250 Loss 0.0239 Accuracy 0.9323 AUC 0.5246\n","Epoch 5 Batch 260 Loss 0.0238 Accuracy 0.9324 AUC 0.5259\n","Epoch 5 Batch 270 Loss 0.0238 Accuracy 0.9325 AUC 0.5199\n","Epoch 5 Batch 280 Loss 0.0237 Accuracy 0.9332 AUC 0.5233\n","Epoch 5 Batch 290 Loss 0.0237 Accuracy 0.9332 AUC 0.5239\n","Epoch 5 Batch 300 Loss 0.0236 Accuracy 0.9335 AUC 0.5232\n","Epoch 5 Batch 310 Loss 0.0237 Accuracy 0.9332 AUC 0.5201\n","Epoch 5 Batch 320 Loss 0.0237 Accuracy 0.9330 AUC 0.5214\n","Epoch 5 Batch 330 Loss 0.0237 Accuracy 0.9330 AUC 0.5224\n","Epoch 5 Batch 340 Loss 0.0237 Accuracy 0.9331 AUC 0.5240\n","Epoch 5 Batch 350 Loss 0.0237 Accuracy 0.9331 AUC 0.5226\n","Epoch 5 Batch 360 Loss 0.0238 Accuracy 0.9329 AUC 0.5213\n","Epoch 5 Batch 370 Loss 0.0238 Accuracy 0.9325 AUC 0.5230\n","Epoch 5 Batch 380 Loss 0.0237 Accuracy 0.9328 AUC 0.5238\n","Epoch 5 Batch 390 Loss 0.0238 Accuracy 0.9326 AUC 0.5241\n","Epoch 5 Batch 400 Loss 0.0238 Accuracy 0.9326 AUC 0.5242\n","Epoch 5 Batch 410 Loss 0.0237 Accuracy 0.9327 AUC 0.5271\n","Epoch 5 Batch 420 Loss 0.0237 Accuracy 0.9329 AUC 0.5286\n","Epoch 5 Batch 430 Loss 0.0236 Accuracy 0.9331 AUC 0.5330\n","Epoch 5 Batch 440 Loss 0.0236 Accuracy 0.9332 AUC 0.5348\n","Epoch 5 Batch 450 Loss 0.0236 Accuracy 0.9330 AUC 0.5352\n","Epoch 5 Batch 460 Loss 0.0237 Accuracy 0.9330 AUC 0.5353\n","Epoch 5 Batch 470 Loss 0.0237 Accuracy 0.9328 AUC 0.5339\n","Epoch 5 Batch 480 Loss 0.0237 Accuracy 0.9328 AUC 0.5336\n","Epoch 5 Batch 490 Loss 0.0237 Accuracy 0.9330 AUC 0.5338\n","Epoch 5 Batch 500 Loss 0.0237 Accuracy 0.9329 AUC 0.5330\n","Epoch 5 Batch 510 Loss 0.0236 Accuracy 0.9330 AUC 0.5340\n","Epoch 5 Batch 520 Loss 0.0237 Accuracy 0.9326 AUC 0.5342\n","Epoch 5 Batch 530 Loss 0.0237 Accuracy 0.9327 AUC 0.5338\n","Epoch 5 Batch 540 Loss 0.0237 Accuracy 0.9327 AUC 0.5324\n","Epoch 5 Batch 550 Loss 0.0237 Accuracy 0.9328 AUC 0.5333\n","Epoch 5 Batch 560 Loss 0.0237 Accuracy 0.9327 AUC 0.5329\n","Epoch 5 Batch 570 Loss 0.0237 Accuracy 0.9327 AUC 0.5334\n","Epoch 5 Batch 580 Loss 0.0237 Accuracy 0.9328 AUC 0.5326\n","Epoch 5 Batch 590 Loss 0.0237 Accuracy 0.9326 AUC 0.5326\n","Epoch 5 Batch 600 Loss 0.0238 Accuracy 0.9325 AUC 0.5322\n","Epoch 5 Batch 610 Loss 0.0238 Accuracy 0.9325 AUC 0.5324\n","Epoch 5 Batch 620 Loss 0.0237 Accuracy 0.9325 AUC 0.5326\n","Epoch 5 Batch 630 Loss 0.0237 Accuracy 0.9326 AUC 0.5321\n","Epoch 5 Batch 640 Loss 0.0238 Accuracy 0.9323 AUC 0.5324\n","Epoch 5 Batch 650 Loss 0.0237 Accuracy 0.9325 AUC 0.5323\n","Epoch 5 Batch 660 Loss 0.0238 Accuracy 0.9325 AUC 0.5316\n","Epoch 5 Batch 670 Loss 0.0238 Accuracy 0.9323 AUC 0.5324\n","Epoch 5 Batch 680 Loss 0.0239 Accuracy 0.9320 AUC 0.5326\n","Epoch 5 Batch 690 Loss 0.0239 Accuracy 0.9317 AUC 0.5340\n","Epoch 5 Batch 700 Loss 0.0239 Accuracy 0.9317 AUC 0.5335\n","Epoch 5 Batch 710 Loss 0.0239 Accuracy 0.9318 AUC 0.5332\n","Epoch 5 Batch 720 Loss 0.0239 Accuracy 0.9319 AUC 0.5333\n","Epoch 5 Batch 730 Loss 0.0238 Accuracy 0.9322 AUC 0.5347\n","Epoch 5 Batch 740 Loss 0.0239 Accuracy 0.9320 AUC 0.5346\n","Epoch 5 Batch 750 Loss 0.0239 Accuracy 0.9318 AUC 0.5352\n","Epoch 5 Batch 760 Loss 0.0240 Accuracy 0.9316 AUC 0.5359\n","Epoch 5 Batch 770 Loss 0.0239 Accuracy 0.9316 AUC 0.5353\n","Epoch 5 Batch 780 Loss 0.0240 Accuracy 0.9316 AUC 0.5353\n","Epoch 5 Batch 790 Loss 0.0239 Accuracy 0.9318 AUC 0.5358\n","Epoch 5 Batch 800 Loss 0.0239 Accuracy 0.9319 AUC 0.5357\n","Epoch 5 Batch 810 Loss 0.0239 Accuracy 0.9319 AUC 0.5365\n","Epoch 5 Batch 820 Loss 0.0239 Accuracy 0.9318 AUC 0.5361\n","Epoch 5 Batch 830 Loss 0.0239 Accuracy 0.9320 AUC 0.5359\n","Epoch 5 Batch 840 Loss 0.0238 Accuracy 0.9320 AUC 0.5371\n","Epoch 5 Batch 850 Loss 0.0239 Accuracy 0.9319 AUC 0.5378\n","Epoch 5 Batch 860 Loss 0.0239 Accuracy 0.9319 AUC 0.5370\n","Epoch 5 Batch 870 Loss 0.0239 Accuracy 0.9320 AUC 0.5367\n","Epoch 5 Batch 880 Loss 0.0239 Accuracy 0.9318 AUC 0.5368\n","Epoch 5 Batch 890 Loss 0.0239 Accuracy 0.9318 AUC 0.5361\n","Epoch 5 Batch 900 Loss 0.0239 Accuracy 0.9320 AUC 0.5360\n","Epoch 5 Batch 910 Loss 0.0238 Accuracy 0.9320 AUC 0.5360\n","Epoch 5 Batch 920 Loss 0.0238 Accuracy 0.9321 AUC 0.5365\n","Epoch 5 Batch 930 Loss 0.0238 Accuracy 0.9321 AUC 0.5373\n","Epoch 5 Batch 940 Loss 0.0238 Accuracy 0.9321 AUC 0.5370\n","Epoch 5 Batch 950 Loss 0.0238 Accuracy 0.9321 AUC 0.5373\n","Epoch 5 Batch 960 Loss 0.0239 Accuracy 0.9319 AUC 0.5378\n","Epoch 5 Batch 970 Loss 0.0238 Accuracy 0.9320 AUC 0.5377\n","Epoch 5 Batch 980 Loss 0.0238 Accuracy 0.9321 AUC 0.5371\n","Epoch 5 Batch 990 Loss 0.0238 Accuracy 0.9321 AUC 0.5377\n","Epoch 5 Batch 1000 Loss 0.0238 Accuracy 0.9321 AUC 0.5378\n","Epoch 5 Batch 1010 Loss 0.0239 Accuracy 0.9319 AUC 0.5392\n","Epoch 5 Batch 1020 Loss 0.0239 Accuracy 0.9318 AUC 0.5397\n","Epoch 5 Batch 1030 Loss 0.0238 Accuracy 0.9319 AUC 0.5396\n","Epoch 5 Batch 1040 Loss 0.0239 Accuracy 0.9318 AUC 0.5396\n","Epoch 5 Batch 1050 Loss 0.0239 Accuracy 0.9318 AUC 0.5398\n","Epoch 5 Batch 1060 Loss 0.0239 Accuracy 0.9318 AUC 0.5394\n","Epoch 5 Batch 1070 Loss 0.0239 Accuracy 0.9318 AUC 0.5397\n","Epoch 5 Batch 1080 Loss 0.0239 Accuracy 0.9318 AUC 0.5400\n","Epoch 5 Batch 1090 Loss 0.0238 Accuracy 0.9319 AUC 0.5391\n","Epoch 5 Batch 1100 Loss 0.0238 Accuracy 0.9320 AUC 0.5392\n","Epoch 5 Batch 1110 Loss 0.0238 Accuracy 0.9319 AUC 0.5395\n","Epoch 5 Batch 1120 Loss 0.0238 Accuracy 0.9321 AUC 0.5405\n","Epoch 5 Batch 1130 Loss 0.0237 Accuracy 0.9323 AUC 0.5413\n","Epoch 5 Batch 1140 Loss 0.0237 Accuracy 0.9323 AUC 0.5415\n","Epoch 5 Batch 1150 Loss 0.0237 Accuracy 0.9325 AUC 0.5421\n","Epoch 5 Batch 1160 Loss 0.0237 Accuracy 0.9323 AUC 0.5419\n","Epoch 5 Batch 1170 Loss 0.0238 Accuracy 0.9322 AUC 0.5425\n","Epoch 5 Batch 1180 Loss 0.0238 Accuracy 0.9321 AUC 0.5423\n","Epoch 5 Batch 1190 Loss 0.0238 Accuracy 0.9322 AUC 0.5420\n","Epoch 5 Batch 1200 Loss 0.0238 Accuracy 0.9320 AUC 0.5424\n","Epoch 5 Batch 1210 Loss 0.0238 Accuracy 0.9320 AUC 0.5425\n","Epoch 5 Batch 1220 Loss 0.0238 Accuracy 0.9320 AUC 0.5418\n","Epoch 5 Batch 1230 Loss 0.0238 Accuracy 0.9321 AUC 0.5420\n","Epoch 5 Batch 1240 Loss 0.0238 Accuracy 0.9321 AUC 0.5416\n","Epoch 5 Batch 1250 Loss 0.0238 Accuracy 0.9322 AUC 0.5416\n","Epoch 5 Batch 1260 Loss 0.0238 Accuracy 0.9322 AUC 0.5419\n","Epoch 5 Batch 1270 Loss 0.0237 Accuracy 0.9324 AUC 0.5417\n","Epoch 5 Batch 1280 Loss 0.0237 Accuracy 0.9324 AUC 0.5412\n","Epoch 5 Batch 1290 Loss 0.0237 Accuracy 0.9324 AUC 0.5412\n","Epoch 5 Batch 1300 Loss 0.0237 Accuracy 0.9324 AUC 0.5410\n","Epoch 5 Batch 1310 Loss 0.0237 Accuracy 0.9324 AUC 0.5407\n","Epoch 5 Batch 1320 Loss 0.0237 Accuracy 0.9325 AUC 0.5404\n","Epoch 5 Batch 1330 Loss 0.0237 Accuracy 0.9324 AUC 0.5404\n","Epoch 5 Batch 1340 Loss 0.0238 Accuracy 0.9323 AUC 0.5408\n","Epoch 5 Batch 1350 Loss 0.0238 Accuracy 0.9322 AUC 0.5408\n","Epoch 5 Batch 1360 Loss 0.0238 Accuracy 0.9322 AUC 0.5405\n","Epoch 5 Batch 1370 Loss 0.0238 Accuracy 0.9323 AUC 0.5406\n","Epoch 5 Batch 1380 Loss 0.0237 Accuracy 0.9323 AUC 0.5411\n","Epoch 5 Batch 1390 Loss 0.0237 Accuracy 0.9324 AUC 0.5417\n","Epoch 5 Batch 1400 Loss 0.0237 Accuracy 0.9325 AUC 0.5418\n","Epoch 5 Batch 1410 Loss 0.0237 Accuracy 0.9324 AUC 0.5428\n","Epoch 5 Batch 1420 Loss 0.0237 Accuracy 0.9326 AUC 0.5427\n","Epoch 5 Batch 1430 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 5 Batch 1440 Loss 0.0237 Accuracy 0.9324 AUC 0.5424\n","Epoch 5 Batch 1450 Loss 0.0237 Accuracy 0.9324 AUC 0.5425\n","Epoch 5 Batch 1460 Loss 0.0237 Accuracy 0.9326 AUC 0.5426\n","Epoch 5 Batch 1470 Loss 0.0237 Accuracy 0.9326 AUC 0.5427\n","Epoch 5 Batch 1480 Loss 0.0236 Accuracy 0.9327 AUC 0.5422\n","Epoch 5 Batch 1490 Loss 0.0237 Accuracy 0.9325 AUC 0.5425\n","Epoch 5 Batch 1500 Loss 0.0237 Accuracy 0.9326 AUC 0.5420\n","Epoch 5 Batch 1510 Loss 0.0237 Accuracy 0.9326 AUC 0.5415\n","Epoch 5 Batch 1520 Loss 0.0236 Accuracy 0.9327 AUC 0.5415\n","Epoch 5 Batch 1530 Loss 0.0237 Accuracy 0.9326 AUC 0.5413\n","Epoch 5 Batch 1540 Loss 0.0237 Accuracy 0.9325 AUC 0.5414\n","Epoch 5 Batch 1550 Loss 0.0237 Accuracy 0.9324 AUC 0.5412\n","Epoch 5 Batch 1560 Loss 0.0237 Accuracy 0.9324 AUC 0.5407\n","Epoch 5 Batch 1570 Loss 0.0237 Accuracy 0.9324 AUC 0.5404\n","Epoch 5 Batch 1580 Loss 0.0237 Accuracy 0.9324 AUC 0.5403\n","Epoch 5 Batch 1590 Loss 0.0237 Accuracy 0.9325 AUC 0.5402\n","Epoch 5 Batch 1600 Loss 0.0237 Accuracy 0.9325 AUC 0.5400\n","Epoch 5 Batch 1610 Loss 0.0237 Accuracy 0.9325 AUC 0.5398\n","Epoch 5 Batch 1620 Loss 0.0237 Accuracy 0.9325 AUC 0.5395\n","Epoch 5 Batch 1630 Loss 0.0237 Accuracy 0.9324 AUC 0.5393\n","Epoch 5 Batch 1640 Loss 0.0237 Accuracy 0.9325 AUC 0.5391\n","Epoch 5 Batch 1650 Loss 0.0237 Accuracy 0.9326 AUC 0.5392\n","Epoch 5 Batch 1660 Loss 0.0237 Accuracy 0.9326 AUC 0.5392\n","Epoch 5 Batch 1670 Loss 0.0237 Accuracy 0.9326 AUC 0.5392\n","Epoch 5 Batch 1680 Loss 0.0237 Accuracy 0.9326 AUC 0.5392\n","Epoch 5 Batch 1690 Loss 0.0237 Accuracy 0.9325 AUC 0.5390\n","Epoch 5 Batch 1700 Loss 0.0237 Accuracy 0.9325 AUC 0.5392\n","Epoch 5 Batch 1710 Loss 0.0237 Accuracy 0.9324 AUC 0.5383\n","Epoch 5 Batch 1720 Loss 0.0237 Accuracy 0.9324 AUC 0.5383\n","Epoch 5 Batch 1730 Loss 0.0237 Accuracy 0.9324 AUC 0.5383\n","Epoch 5 Batch 1740 Loss 0.0237 Accuracy 0.9324 AUC 0.5383\n","Epoch 5 Batch 1750 Loss 0.0237 Accuracy 0.9324 AUC 0.5381\n","Epoch 5 Batch 1760 Loss 0.0237 Accuracy 0.9324 AUC 0.5380\n","Epoch 5 Batch 1770 Loss 0.0237 Accuracy 0.9323 AUC 0.5379\n","Epoch 5 Batch 1780 Loss 0.0237 Accuracy 0.9324 AUC 0.5379\n","Epoch 5 Batch 1790 Loss 0.0237 Accuracy 0.9325 AUC 0.5379\n","Epoch 5 Batch 1800 Loss 0.0237 Accuracy 0.9325 AUC 0.5381\n","Epoch 5 Batch 1810 Loss 0.0237 Accuracy 0.9325 AUC 0.5381\n","Epoch 5 Batch 1820 Loss 0.0237 Accuracy 0.9325 AUC 0.5378\n","Epoch 5 Batch 1830 Loss 0.0237 Accuracy 0.9324 AUC 0.5378\n","Epoch 5 Batch 1840 Loss 0.0237 Accuracy 0.9325 AUC 0.5376\n","Epoch 5 Batch 1850 Loss 0.0237 Accuracy 0.9325 AUC 0.5375\n","Epoch 5 Batch 1860 Loss 0.0237 Accuracy 0.9325 AUC 0.5374\n","Epoch 5 Batch 1870 Loss 0.0237 Accuracy 0.9325 AUC 0.5373\n","Epoch 5 Batch 1880 Loss 0.0237 Accuracy 0.9325 AUC 0.5372\n","Epoch 5 Batch 1890 Loss 0.0237 Accuracy 0.9324 AUC 0.5369\n","Epoch 5 Batch 1900 Loss 0.0237 Accuracy 0.9324 AUC 0.5368\n","Epoch 5 Batch 1910 Loss 0.0237 Accuracy 0.9324 AUC 0.5365\n","Epoch 5 Batch 1920 Loss 0.0237 Accuracy 0.9324 AUC 0.5363\n","Epoch 5 Batch 1930 Loss 0.0237 Accuracy 0.9324 AUC 0.5364\n","Epoch 5 Batch 1940 Loss 0.0237 Accuracy 0.9324 AUC 0.5365\n","Epoch 5 Batch 1950 Loss 0.0237 Accuracy 0.9325 AUC 0.5370\n","Epoch 5 Batch 1960 Loss 0.0237 Accuracy 0.9325 AUC 0.5368\n","Epoch 5 Batch 1970 Loss 0.0237 Accuracy 0.9325 AUC 0.5369\n","Epoch 5 Batch 1980 Loss 0.0237 Accuracy 0.9325 AUC 0.5369\n","Epoch 5 Batch 1990 Loss 0.0237 Accuracy 0.9325 AUC 0.5373\n","Epoch 5 Batch 2000 Loss 0.0237 Accuracy 0.9325 AUC 0.5374\n","Epoch 5 Batch 2010 Loss 0.0237 Accuracy 0.9325 AUC 0.5374\n","Epoch 5 Batch 2020 Loss 0.0237 Accuracy 0.9326 AUC 0.5374\n","Epoch 5 Batch 2030 Loss 0.0237 Accuracy 0.9325 AUC 0.5375\n","Epoch 5 Batch 2040 Loss 0.0237 Accuracy 0.9325 AUC 0.5375\n","Epoch 5 Batch 2050 Loss 0.0237 Accuracy 0.9324 AUC 0.5377\n","Epoch 5 Batch 2060 Loss 0.0237 Accuracy 0.9325 AUC 0.5374\n","Epoch 5 Batch 2070 Loss 0.0237 Accuracy 0.9325 AUC 0.5373\n","Epoch 5 Batch 2080 Loss 0.0237 Accuracy 0.9324 AUC 0.5374\n","Epoch 5 Batch 2090 Loss 0.0237 Accuracy 0.9325 AUC 0.5376\n","Epoch 5 Batch 2100 Loss 0.0237 Accuracy 0.9325 AUC 0.5376\n","Saving checkpoint for epoch 5 at checkpoints/train/ckpt-1\n","Epoch 5 Loss 0.0237 Accuracy 0.9325\n","Time taken for 1 epoch: 712.3849320411682 secs\n","\n","Epoch 6 Batch 0 Loss 0.0185 Accuracy 0.9531 AUC 0.5929\n","Epoch 6 Batch 10 Loss 0.0236 Accuracy 0.9332 AUC 0.5089\n","Epoch 6 Batch 20 Loss 0.0252 Accuracy 0.9256 AUC 0.5581\n","Epoch 6 Batch 30 Loss 0.0236 Accuracy 0.9325 AUC 0.5485\n","Epoch 6 Batch 40 Loss 0.0244 Accuracy 0.9303 AUC 0.5260\n","Epoch 6 Batch 50 Loss 0.0241 Accuracy 0.9314 AUC 0.5219\n","Epoch 6 Batch 60 Loss 0.0245 Accuracy 0.9293 AUC 0.5379\n","Epoch 6 Batch 70 Loss 0.0244 Accuracy 0.9298 AUC 0.5379\n","Epoch 6 Batch 80 Loss 0.0246 Accuracy 0.9290 AUC 0.5367\n","Epoch 6 Batch 90 Loss 0.0245 Accuracy 0.9296 AUC 0.5361\n","Epoch 6 Batch 100 Loss 0.0244 Accuracy 0.9299 AUC 0.5295\n","Epoch 6 Batch 110 Loss 0.0246 Accuracy 0.9293 AUC 0.5275\n","Epoch 6 Batch 120 Loss 0.0244 Accuracy 0.9301 AUC 0.5285\n","Epoch 6 Batch 130 Loss 0.0243 Accuracy 0.9302 AUC 0.5315\n","Epoch 6 Batch 140 Loss 0.0243 Accuracy 0.9305 AUC 0.5300\n","Epoch 6 Batch 150 Loss 0.0242 Accuracy 0.9308 AUC 0.5249\n","Epoch 6 Batch 160 Loss 0.0243 Accuracy 0.9303 AUC 0.5257\n","Epoch 6 Batch 170 Loss 0.0244 Accuracy 0.9301 AUC 0.5238\n","Epoch 6 Batch 180 Loss 0.0244 Accuracy 0.9302 AUC 0.5260\n","Epoch 6 Batch 190 Loss 0.0243 Accuracy 0.9305 AUC 0.5238\n","Epoch 6 Batch 200 Loss 0.0244 Accuracy 0.9301 AUC 0.5252\n","Epoch 6 Batch 210 Loss 0.0241 Accuracy 0.9310 AUC 0.5261\n","Epoch 6 Batch 220 Loss 0.0240 Accuracy 0.9314 AUC 0.5247\n","Epoch 6 Batch 230 Loss 0.0238 Accuracy 0.9323 AUC 0.5291\n","Epoch 6 Batch 240 Loss 0.0237 Accuracy 0.9326 AUC 0.5301\n","Epoch 6 Batch 250 Loss 0.0238 Accuracy 0.9323 AUC 0.5263\n","Epoch 6 Batch 260 Loss 0.0238 Accuracy 0.9324 AUC 0.5231\n","Epoch 6 Batch 270 Loss 0.0238 Accuracy 0.9325 AUC 0.5209\n","Epoch 6 Batch 280 Loss 0.0236 Accuracy 0.9332 AUC 0.5228\n","Epoch 6 Batch 290 Loss 0.0236 Accuracy 0.9332 AUC 0.5241\n","Epoch 6 Batch 300 Loss 0.0235 Accuracy 0.9335 AUC 0.5263\n","Epoch 6 Batch 310 Loss 0.0236 Accuracy 0.9332 AUC 0.5223\n","Epoch 6 Batch 320 Loss 0.0237 Accuracy 0.9330 AUC 0.5236\n","Epoch 6 Batch 330 Loss 0.0237 Accuracy 0.9330 AUC 0.5234\n","Epoch 6 Batch 340 Loss 0.0236 Accuracy 0.9331 AUC 0.5239\n","Epoch 6 Batch 350 Loss 0.0236 Accuracy 0.9331 AUC 0.5234\n","Epoch 6 Batch 360 Loss 0.0237 Accuracy 0.9329 AUC 0.5223\n","Epoch 6 Batch 370 Loss 0.0238 Accuracy 0.9325 AUC 0.5228\n","Epoch 6 Batch 380 Loss 0.0237 Accuracy 0.9328 AUC 0.5237\n","Epoch 6 Batch 390 Loss 0.0238 Accuracy 0.9326 AUC 0.5225\n","Epoch 6 Batch 400 Loss 0.0238 Accuracy 0.9326 AUC 0.5222\n","Epoch 6 Batch 410 Loss 0.0237 Accuracy 0.9327 AUC 0.5239\n","Epoch 6 Batch 420 Loss 0.0237 Accuracy 0.9329 AUC 0.5250\n","Epoch 6 Batch 430 Loss 0.0236 Accuracy 0.9331 AUC 0.5284\n","Epoch 6 Batch 440 Loss 0.0236 Accuracy 0.9332 AUC 0.5299\n","Epoch 6 Batch 450 Loss 0.0236 Accuracy 0.9330 AUC 0.5319\n","Epoch 6 Batch 460 Loss 0.0236 Accuracy 0.9330 AUC 0.5321\n","Epoch 6 Batch 470 Loss 0.0237 Accuracy 0.9328 AUC 0.5302\n","Epoch 6 Batch 480 Loss 0.0237 Accuracy 0.9328 AUC 0.5298\n","Epoch 6 Batch 490 Loss 0.0236 Accuracy 0.9330 AUC 0.5297\n","Epoch 6 Batch 500 Loss 0.0236 Accuracy 0.9329 AUC 0.5303\n","Epoch 6 Batch 510 Loss 0.0236 Accuracy 0.9330 AUC 0.5315\n","Epoch 6 Batch 520 Loss 0.0237 Accuracy 0.9326 AUC 0.5307\n","Epoch 6 Batch 530 Loss 0.0237 Accuracy 0.9327 AUC 0.5298\n","Epoch 6 Batch 540 Loss 0.0237 Accuracy 0.9327 AUC 0.5286\n","Epoch 6 Batch 550 Loss 0.0237 Accuracy 0.9328 AUC 0.5284\n","Epoch 6 Batch 560 Loss 0.0237 Accuracy 0.9327 AUC 0.5279\n","Epoch 6 Batch 570 Loss 0.0237 Accuracy 0.9327 AUC 0.5277\n","Epoch 6 Batch 580 Loss 0.0237 Accuracy 0.9328 AUC 0.5278\n","Epoch 6 Batch 590 Loss 0.0237 Accuracy 0.9326 AUC 0.5274\n","Epoch 6 Batch 600 Loss 0.0238 Accuracy 0.9325 AUC 0.5276\n","Epoch 6 Batch 610 Loss 0.0238 Accuracy 0.9325 AUC 0.5274\n","Epoch 6 Batch 620 Loss 0.0237 Accuracy 0.9325 AUC 0.5280\n","Epoch 6 Batch 630 Loss 0.0237 Accuracy 0.9326 AUC 0.5276\n","Epoch 6 Batch 640 Loss 0.0238 Accuracy 0.9323 AUC 0.5282\n","Epoch 6 Batch 650 Loss 0.0237 Accuracy 0.9325 AUC 0.5285\n","Epoch 6 Batch 660 Loss 0.0237 Accuracy 0.9325 AUC 0.5284\n","Epoch 6 Batch 670 Loss 0.0238 Accuracy 0.9323 AUC 0.5292\n","Epoch 6 Batch 680 Loss 0.0239 Accuracy 0.9320 AUC 0.5290\n","Epoch 6 Batch 690 Loss 0.0239 Accuracy 0.9317 AUC 0.5303\n","Epoch 6 Batch 700 Loss 0.0239 Accuracy 0.9317 AUC 0.5305\n","Epoch 6 Batch 710 Loss 0.0239 Accuracy 0.9318 AUC 0.5311\n","Epoch 6 Batch 720 Loss 0.0239 Accuracy 0.9319 AUC 0.5314\n","Epoch 6 Batch 730 Loss 0.0238 Accuracy 0.9322 AUC 0.5328\n","Epoch 6 Batch 740 Loss 0.0238 Accuracy 0.9320 AUC 0.5329\n","Epoch 6 Batch 750 Loss 0.0239 Accuracy 0.9318 AUC 0.5336\n","Epoch 6 Batch 760 Loss 0.0239 Accuracy 0.9316 AUC 0.5334\n","Epoch 6 Batch 770 Loss 0.0239 Accuracy 0.9316 AUC 0.5327\n","Epoch 6 Batch 780 Loss 0.0239 Accuracy 0.9316 AUC 0.5328\n","Epoch 6 Batch 790 Loss 0.0239 Accuracy 0.9318 AUC 0.5331\n","Epoch 6 Batch 800 Loss 0.0239 Accuracy 0.9319 AUC 0.5337\n","Epoch 6 Batch 810 Loss 0.0239 Accuracy 0.9319 AUC 0.5342\n","Epoch 6 Batch 820 Loss 0.0239 Accuracy 0.9318 AUC 0.5345\n","Epoch 6 Batch 830 Loss 0.0238 Accuracy 0.9320 AUC 0.5348\n","Epoch 6 Batch 840 Loss 0.0238 Accuracy 0.9320 AUC 0.5364\n","Epoch 6 Batch 850 Loss 0.0238 Accuracy 0.9319 AUC 0.5375\n","Epoch 6 Batch 860 Loss 0.0239 Accuracy 0.9319 AUC 0.5371\n","Epoch 6 Batch 870 Loss 0.0238 Accuracy 0.9320 AUC 0.5375\n","Epoch 6 Batch 880 Loss 0.0239 Accuracy 0.9318 AUC 0.5370\n","Epoch 6 Batch 890 Loss 0.0239 Accuracy 0.9318 AUC 0.5367\n","Epoch 6 Batch 900 Loss 0.0238 Accuracy 0.9320 AUC 0.5369\n","Epoch 6 Batch 910 Loss 0.0238 Accuracy 0.9320 AUC 0.5365\n","Epoch 6 Batch 920 Loss 0.0238 Accuracy 0.9321 AUC 0.5369\n","Epoch 6 Batch 930 Loss 0.0238 Accuracy 0.9321 AUC 0.5372\n","Epoch 6 Batch 940 Loss 0.0238 Accuracy 0.9321 AUC 0.5367\n","Epoch 6 Batch 950 Loss 0.0238 Accuracy 0.9321 AUC 0.5365\n","Epoch 6 Batch 960 Loss 0.0238 Accuracy 0.9319 AUC 0.5372\n","Epoch 6 Batch 970 Loss 0.0238 Accuracy 0.9320 AUC 0.5367\n","Epoch 6 Batch 980 Loss 0.0238 Accuracy 0.9321 AUC 0.5364\n","Epoch 6 Batch 990 Loss 0.0238 Accuracy 0.9321 AUC 0.5365\n","Epoch 6 Batch 1010 Loss 0.0238 Accuracy 0.9319 AUC 0.5372\n","Epoch 6 Batch 1020 Loss 0.0239 Accuracy 0.9318 AUC 0.5376\n","Epoch 6 Batch 1030 Loss 0.0238 Accuracy 0.9319 AUC 0.5381\n","Epoch 6 Batch 1040 Loss 0.0238 Accuracy 0.9318 AUC 0.5386\n","Epoch 6 Batch 1050 Loss 0.0239 Accuracy 0.9318 AUC 0.5385\n","Epoch 6 Batch 1060 Loss 0.0239 Accuracy 0.9318 AUC 0.5378\n","Epoch 6 Batch 1070 Loss 0.0238 Accuracy 0.9318 AUC 0.5378\n","Epoch 6 Batch 1080 Loss 0.0238 Accuracy 0.9318 AUC 0.5379\n","Epoch 6 Batch 1090 Loss 0.0238 Accuracy 0.9319 AUC 0.5372\n","Epoch 6 Batch 1100 Loss 0.0238 Accuracy 0.9320 AUC 0.5373\n","Epoch 6 Batch 1110 Loss 0.0238 Accuracy 0.9319 AUC 0.5372\n","Epoch 6 Batch 1120 Loss 0.0238 Accuracy 0.9321 AUC 0.5380\n","Epoch 6 Batch 1130 Loss 0.0237 Accuracy 0.9323 AUC 0.5387\n","Epoch 6 Batch 1140 Loss 0.0237 Accuracy 0.9323 AUC 0.5388\n","Epoch 6 Batch 1150 Loss 0.0237 Accuracy 0.9325 AUC 0.5394\n","Epoch 6 Batch 1160 Loss 0.0237 Accuracy 0.9323 AUC 0.5390\n","Epoch 6 Batch 1170 Loss 0.0238 Accuracy 0.9322 AUC 0.5396\n","Epoch 6 Batch 1180 Loss 0.0238 Accuracy 0.9321 AUC 0.5395\n","Epoch 6 Batch 1190 Loss 0.0238 Accuracy 0.9322 AUC 0.5391\n","Epoch 6 Batch 1200 Loss 0.0238 Accuracy 0.9320 AUC 0.5395\n","Epoch 6 Batch 1210 Loss 0.0238 Accuracy 0.9320 AUC 0.5394\n","Epoch 6 Batch 1220 Loss 0.0238 Accuracy 0.9320 AUC 0.5395\n","Epoch 6 Batch 1230 Loss 0.0238 Accuracy 0.9321 AUC 0.5393\n","Epoch 6 Batch 1240 Loss 0.0238 Accuracy 0.9321 AUC 0.5388\n","Epoch 6 Batch 1250 Loss 0.0238 Accuracy 0.9322 AUC 0.5387\n","Epoch 6 Batch 1260 Loss 0.0237 Accuracy 0.9322 AUC 0.5392\n","Epoch 6 Batch 1270 Loss 0.0237 Accuracy 0.9324 AUC 0.5392\n","Epoch 6 Batch 1280 Loss 0.0237 Accuracy 0.9324 AUC 0.5386\n","Epoch 6 Batch 1290 Loss 0.0237 Accuracy 0.9324 AUC 0.5387\n","Epoch 6 Batch 1300 Loss 0.0237 Accuracy 0.9324 AUC 0.5390\n","Epoch 6 Batch 1310 Loss 0.0237 Accuracy 0.9324 AUC 0.5387\n","Epoch 6 Batch 1320 Loss 0.0237 Accuracy 0.9325 AUC 0.5389\n","Epoch 6 Batch 1330 Loss 0.0237 Accuracy 0.9324 AUC 0.5390\n","Epoch 6 Batch 1340 Loss 0.0237 Accuracy 0.9323 AUC 0.5395\n","Epoch 6 Batch 1350 Loss 0.0238 Accuracy 0.9322 AUC 0.5395\n","Epoch 6 Batch 1360 Loss 0.0238 Accuracy 0.9322 AUC 0.5394\n","Epoch 6 Batch 1370 Loss 0.0237 Accuracy 0.9323 AUC 0.5396\n","Epoch 6 Batch 1380 Loss 0.0237 Accuracy 0.9323 AUC 0.5398\n","Epoch 6 Batch 1390 Loss 0.0237 Accuracy 0.9324 AUC 0.5398\n","Epoch 6 Batch 1400 Loss 0.0237 Accuracy 0.9325 AUC 0.5402\n","Epoch 6 Batch 1410 Loss 0.0237 Accuracy 0.9324 AUC 0.5406\n","Epoch 6 Batch 1420 Loss 0.0237 Accuracy 0.9326 AUC 0.5403\n","Epoch 6 Batch 1430 Loss 0.0237 Accuracy 0.9325 AUC 0.5400\n","Epoch 6 Batch 1440 Loss 0.0237 Accuracy 0.9324 AUC 0.5401\n","Epoch 6 Batch 1450 Loss 0.0237 Accuracy 0.9324 AUC 0.5403\n","Epoch 6 Batch 1460 Loss 0.0237 Accuracy 0.9326 AUC 0.5403\n","Epoch 6 Batch 1470 Loss 0.0236 Accuracy 0.9326 AUC 0.5401\n","Epoch 6 Batch 1480 Loss 0.0236 Accuracy 0.9327 AUC 0.5402\n","Epoch 6 Batch 1490 Loss 0.0237 Accuracy 0.9325 AUC 0.5405\n","Epoch 6 Batch 1500 Loss 0.0237 Accuracy 0.9326 AUC 0.5402\n","Epoch 6 Batch 1510 Loss 0.0236 Accuracy 0.9326 AUC 0.5398\n","Epoch 6 Batch 1520 Loss 0.0236 Accuracy 0.9327 AUC 0.5398\n","Epoch 6 Batch 1530 Loss 0.0237 Accuracy 0.9326 AUC 0.5400\n","Epoch 6 Batch 1540 Loss 0.0237 Accuracy 0.9325 AUC 0.5402\n","Epoch 6 Batch 1550 Loss 0.0237 Accuracy 0.9324 AUC 0.5405\n","Epoch 6 Batch 1560 Loss 0.0237 Accuracy 0.9324 AUC 0.5404\n","Epoch 6 Batch 1570 Loss 0.0237 Accuracy 0.9324 AUC 0.5404\n","Epoch 6 Batch 1580 Loss 0.0237 Accuracy 0.9324 AUC 0.5403\n","Epoch 6 Batch 1590 Loss 0.0237 Accuracy 0.9325 AUC 0.5404\n","Epoch 6 Batch 1600 Loss 0.0237 Accuracy 0.9325 AUC 0.5404\n","Epoch 6 Batch 1610 Loss 0.0237 Accuracy 0.9325 AUC 0.5404\n","Epoch 6 Batch 1620 Loss 0.0237 Accuracy 0.9325 AUC 0.5404\n","Epoch 6 Batch 1630 Loss 0.0237 Accuracy 0.9324 AUC 0.5404\n","Epoch 6 Batch 1640 Loss 0.0237 Accuracy 0.9325 AUC 0.5409\n","Epoch 6 Batch 1650 Loss 0.0236 Accuracy 0.9326 AUC 0.5415\n","Epoch 6 Batch 1660 Loss 0.0236 Accuracy 0.9326 AUC 0.5416\n","Epoch 6 Batch 1670 Loss 0.0236 Accuracy 0.9326 AUC 0.5418\n","Epoch 6 Batch 1680 Loss 0.0236 Accuracy 0.9326 AUC 0.5418\n","Epoch 6 Batch 1690 Loss 0.0237 Accuracy 0.9325 AUC 0.5420\n","Epoch 6 Batch 1700 Loss 0.0237 Accuracy 0.9325 AUC 0.5422\n","Epoch 6 Batch 1710 Loss 0.0237 Accuracy 0.9324 AUC 0.5417\n","Epoch 6 Batch 1720 Loss 0.0237 Accuracy 0.9324 AUC 0.5417\n","Epoch 6 Batch 1730 Loss 0.0237 Accuracy 0.9324 AUC 0.5418\n","Epoch 6 Batch 1740 Loss 0.0237 Accuracy 0.9324 AUC 0.5420\n","Epoch 6 Batch 1750 Loss 0.0237 Accuracy 0.9324 AUC 0.5422\n","Epoch 6 Batch 1760 Loss 0.0237 Accuracy 0.9324 AUC 0.5425\n","Epoch 6 Batch 1770 Loss 0.0237 Accuracy 0.9323 AUC 0.5425\n","Epoch 6 Batch 1780 Loss 0.0237 Accuracy 0.9324 AUC 0.5428\n","Epoch 6 Batch 1790 Loss 0.0237 Accuracy 0.9325 AUC 0.5430\n","Epoch 6 Batch 1800 Loss 0.0236 Accuracy 0.9325 AUC 0.5431\n","Epoch 6 Batch 1810 Loss 0.0237 Accuracy 0.9325 AUC 0.5431\n","Epoch 6 Batch 1820 Loss 0.0237 Accuracy 0.9325 AUC 0.5434\n","Epoch 6 Batch 1830 Loss 0.0237 Accuracy 0.9324 AUC 0.5434\n","Epoch 6 Batch 1840 Loss 0.0237 Accuracy 0.9325 AUC 0.5432\n","Epoch 6 Batch 1850 Loss 0.0237 Accuracy 0.9325 AUC 0.5429\n","Epoch 6 Batch 1860 Loss 0.0237 Accuracy 0.9325 AUC 0.5429\n","Epoch 6 Batch 1870 Loss 0.0237 Accuracy 0.9325 AUC 0.5427\n","Epoch 6 Batch 1880 Loss 0.0237 Accuracy 0.9325 AUC 0.5427\n","Epoch 6 Batch 1890 Loss 0.0237 Accuracy 0.9324 AUC 0.5425\n","Epoch 6 Batch 1900 Loss 0.0237 Accuracy 0.9324 AUC 0.5424\n","Epoch 6 Batch 1910 Loss 0.0237 Accuracy 0.9324 AUC 0.5422\n","Epoch 6 Batch 1920 Loss 0.0237 Accuracy 0.9324 AUC 0.5419\n","Epoch 6 Batch 1930 Loss 0.0237 Accuracy 0.9324 AUC 0.5420\n","Epoch 6 Batch 1940 Loss 0.0237 Accuracy 0.9324 AUC 0.5420\n","Epoch 6 Batch 1950 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 6 Batch 1960 Loss 0.0237 Accuracy 0.9325 AUC 0.5424\n","Epoch 6 Batch 1970 Loss 0.0237 Accuracy 0.9325 AUC 0.5423\n","Epoch 6 Batch 1980 Loss 0.0237 Accuracy 0.9325 AUC 0.5425\n","Epoch 6 Batch 1990 Loss 0.0236 Accuracy 0.9325 AUC 0.5429\n","Epoch 6 Batch 2000 Loss 0.0236 Accuracy 0.9325 AUC 0.5431\n","Epoch 6 Batch 2010 Loss 0.0236 Accuracy 0.9325 AUC 0.5429\n","Epoch 6 Batch 2020 Loss 0.0236 Accuracy 0.9326 AUC 0.5429\n","Epoch 6 Batch 2030 Loss 0.0236 Accuracy 0.9325 AUC 0.5431\n","Epoch 6 Batch 2040 Loss 0.0236 Accuracy 0.9325 AUC 0.5431\n","Epoch 6 Batch 2050 Loss 0.0237 Accuracy 0.9324 AUC 0.5432\n","Epoch 6 Batch 2060 Loss 0.0237 Accuracy 0.9325 AUC 0.5430\n","Epoch 6 Batch 2070 Loss 0.0237 Accuracy 0.9325 AUC 0.5428\n","Epoch 6 Batch 2080 Loss 0.0237 Accuracy 0.9324 AUC 0.5428\n","Epoch 6 Batch 2090 Loss 0.0237 Accuracy 0.9325 AUC 0.5429\n","Epoch 6 Batch 2100 Loss 0.0236 Accuracy 0.9325 AUC 0.5430\n","Epoch 6 Loss 0.0237 Accuracy 0.9325\n","Time taken for 1 epoch: 709.7791438102722 secs\n","\n","Epoch 7 Batch 0 Loss 0.0184 Accuracy 0.9531 AUC 0.6557\n","Epoch 7 Batch 10 Loss 0.0237 Accuracy 0.9332 AUC 0.4851\n","Epoch 7 Batch 20 Loss 0.0254 Accuracy 0.9256 AUC 0.5374\n","Epoch 7 Batch 30 Loss 0.0238 Accuracy 0.9325 AUC 0.5108\n","Epoch 7 Batch 40 Loss 0.0244 Accuracy 0.9303 AUC 0.4976\n","Epoch 7 Batch 50 Loss 0.0241 Accuracy 0.9314 AUC 0.5086\n","Epoch 7 Batch 60 Loss 0.0246 Accuracy 0.9293 AUC 0.5102\n","Epoch 7 Batch 70 Loss 0.0245 Accuracy 0.9298 AUC 0.5143\n","Epoch 7 Batch 80 Loss 0.0247 Accuracy 0.9290 AUC 0.5059\n","Epoch 7 Batch 90 Loss 0.0246 Accuracy 0.9296 AUC 0.5030\n","Epoch 7 Batch 100 Loss 0.0245 Accuracy 0.9299 AUC 0.5025\n","Epoch 7 Batch 110 Loss 0.0247 Accuracy 0.9293 AUC 0.5006\n","Epoch 7 Batch 120 Loss 0.0244 Accuracy 0.9301 AUC 0.5007\n","Epoch 7 Batch 130 Loss 0.0244 Accuracy 0.9302 AUC 0.4985\n","Epoch 7 Batch 140 Loss 0.0243 Accuracy 0.9305 AUC 0.4999\n","Epoch 7 Batch 150 Loss 0.0243 Accuracy 0.9308 AUC 0.4995\n","Epoch 7 Batch 160 Loss 0.0244 Accuracy 0.9303 AUC 0.5036\n","Epoch 7 Batch 170 Loss 0.0244 Accuracy 0.9301 AUC 0.5041\n","Epoch 7 Batch 180 Loss 0.0244 Accuracy 0.9302 AUC 0.5051\n","Epoch 7 Batch 190 Loss 0.0243 Accuracy 0.9305 AUC 0.5036\n","Epoch 7 Batch 200 Loss 0.0244 Accuracy 0.9301 AUC 0.5073\n","Epoch 7 Batch 210 Loss 0.0242 Accuracy 0.9310 AUC 0.5075\n","Epoch 7 Batch 220 Loss 0.0240 Accuracy 0.9314 AUC 0.5070\n","Epoch 7 Batch 230 Loss 0.0238 Accuracy 0.9323 AUC 0.5134\n","Epoch 7 Batch 240 Loss 0.0237 Accuracy 0.9326 AUC 0.5143\n","Epoch 7 Batch 250 Loss 0.0238 Accuracy 0.9323 AUC 0.5124\n","Epoch 7 Batch 260 Loss 0.0238 Accuracy 0.9324 AUC 0.5115\n","Epoch 7 Batch 270 Loss 0.0238 Accuracy 0.9325 AUC 0.5098\n","Epoch 7 Batch 280 Loss 0.0236 Accuracy 0.9332 AUC 0.5127\n","Epoch 7 Batch 290 Loss 0.0236 Accuracy 0.9332 AUC 0.5142\n","Epoch 7 Batch 300 Loss 0.0235 Accuracy 0.9335 AUC 0.5168\n","Epoch 7 Batch 310 Loss 0.0236 Accuracy 0.9332 AUC 0.5138\n","Epoch 7 Batch 320 Loss 0.0236 Accuracy 0.9330 AUC 0.5146\n","Epoch 7 Batch 330 Loss 0.0236 Accuracy 0.9330 AUC 0.5149\n","Epoch 7 Batch 340 Loss 0.0236 Accuracy 0.9331 AUC 0.5147\n","Epoch 7 Batch 350 Loss 0.0236 Accuracy 0.9331 AUC 0.5142\n","Epoch 7 Batch 360 Loss 0.0237 Accuracy 0.9329 AUC 0.5139\n","Epoch 7 Batch 370 Loss 0.0238 Accuracy 0.9325 AUC 0.5150\n","Epoch 7 Batch 380 Loss 0.0237 Accuracy 0.9328 AUC 0.5158\n","Epoch 7 Batch 390 Loss 0.0237 Accuracy 0.9326 AUC 0.5158\n","Epoch 7 Batch 400 Loss 0.0238 Accuracy 0.9326 AUC 0.5171\n","Epoch 7 Batch 410 Loss 0.0237 Accuracy 0.9327 AUC 0.5195\n","Epoch 7 Batch 420 Loss 0.0236 Accuracy 0.9329 AUC 0.5222\n","Epoch 7 Batch 430 Loss 0.0236 Accuracy 0.9331 AUC 0.5266\n","Epoch 7 Batch 440 Loss 0.0235 Accuracy 0.9332 AUC 0.5268\n","Epoch 7 Batch 450 Loss 0.0236 Accuracy 0.9330 AUC 0.5278\n","Epoch 7 Batch 460 Loss 0.0236 Accuracy 0.9330 AUC 0.5282\n","Epoch 7 Batch 470 Loss 0.0237 Accuracy 0.9328 AUC 0.5276\n","Epoch 7 Batch 480 Loss 0.0237 Accuracy 0.9328 AUC 0.5285\n","Epoch 7 Batch 490 Loss 0.0236 Accuracy 0.9330 AUC 0.5279\n","Epoch 7 Batch 500 Loss 0.0236 Accuracy 0.9329 AUC 0.5282\n","Epoch 7 Batch 510 Loss 0.0236 Accuracy 0.9330 AUC 0.5290\n","Epoch 7 Batch 520 Loss 0.0237 Accuracy 0.9326 AUC 0.5286\n","Epoch 7 Batch 530 Loss 0.0237 Accuracy 0.9327 AUC 0.5279\n","Epoch 7 Batch 540 Loss 0.0237 Accuracy 0.9327 AUC 0.5263\n","Epoch 7 Batch 550 Loss 0.0237 Accuracy 0.9328 AUC 0.5261\n","Epoch 7 Batch 560 Loss 0.0237 Accuracy 0.9327 AUC 0.5252\n","Epoch 7 Batch 570 Loss 0.0237 Accuracy 0.9327 AUC 0.5254\n","Epoch 7 Batch 580 Loss 0.0237 Accuracy 0.9328 AUC 0.5254\n","Epoch 7 Batch 590 Loss 0.0237 Accuracy 0.9326 AUC 0.5252\n","Epoch 7 Batch 600 Loss 0.0237 Accuracy 0.9325 AUC 0.5252\n","Epoch 7 Batch 610 Loss 0.0237 Accuracy 0.9325 AUC 0.5251\n","Epoch 7 Batch 620 Loss 0.0237 Accuracy 0.9325 AUC 0.5257\n","Epoch 7 Batch 630 Loss 0.0237 Accuracy 0.9326 AUC 0.5257\n","Epoch 7 Batch 640 Loss 0.0238 Accuracy 0.9323 AUC 0.5269\n","Epoch 7 Batch 650 Loss 0.0237 Accuracy 0.9325 AUC 0.5273\n","Epoch 7 Batch 660 Loss 0.0237 Accuracy 0.9325 AUC 0.5269\n","Epoch 7 Batch 670 Loss 0.0238 Accuracy 0.9323 AUC 0.5278\n","Epoch 7 Batch 680 Loss 0.0238 Accuracy 0.9320 AUC 0.5280\n","Epoch 7 Batch 690 Loss 0.0239 Accuracy 0.9317 AUC 0.5294\n","Epoch 7 Batch 700 Loss 0.0239 Accuracy 0.9317 AUC 0.5294\n","Epoch 7 Batch 710 Loss 0.0239 Accuracy 0.9318 AUC 0.5302\n","Epoch 7 Batch 720 Loss 0.0239 Accuracy 0.9319 AUC 0.5309\n","Epoch 7 Batch 730 Loss 0.0238 Accuracy 0.9322 AUC 0.5321\n","Epoch 7 Batch 740 Loss 0.0238 Accuracy 0.9320 AUC 0.5325\n","Epoch 7 Batch 750 Loss 0.0239 Accuracy 0.9318 AUC 0.5324\n","Epoch 7 Batch 760 Loss 0.0239 Accuracy 0.9316 AUC 0.5331\n","Epoch 7 Batch 770 Loss 0.0239 Accuracy 0.9316 AUC 0.5331\n","Epoch 7 Batch 780 Loss 0.0239 Accuracy 0.9316 AUC 0.5331\n","Epoch 7 Batch 790 Loss 0.0239 Accuracy 0.9318 AUC 0.5345\n","Epoch 7 Batch 800 Loss 0.0238 Accuracy 0.9319 AUC 0.5349\n","Epoch 7 Batch 810 Loss 0.0238 Accuracy 0.9319 AUC 0.5357\n","Epoch 7 Batch 820 Loss 0.0239 Accuracy 0.9318 AUC 0.5365\n","Epoch 7 Batch 830 Loss 0.0238 Accuracy 0.9320 AUC 0.5370\n","Epoch 7 Batch 840 Loss 0.0238 Accuracy 0.9320 AUC 0.5385\n","Epoch 7 Batch 850 Loss 0.0238 Accuracy 0.9319 AUC 0.5402\n","Epoch 7 Batch 860 Loss 0.0238 Accuracy 0.9319 AUC 0.5396\n","Epoch 7 Batch 870 Loss 0.0238 Accuracy 0.9320 AUC 0.5401\n","Epoch 7 Batch 880 Loss 0.0239 Accuracy 0.9318 AUC 0.5397\n","Epoch 7 Batch 890 Loss 0.0238 Accuracy 0.9318 AUC 0.5392\n","Epoch 7 Batch 900 Loss 0.0238 Accuracy 0.9320 AUC 0.5399\n","Epoch 7 Batch 910 Loss 0.0238 Accuracy 0.9320 AUC 0.5398\n","Epoch 7 Batch 920 Loss 0.0238 Accuracy 0.9321 AUC 0.5405\n","Epoch 7 Batch 930 Loss 0.0238 Accuracy 0.9321 AUC 0.5411\n","Epoch 7 Batch 940 Loss 0.0238 Accuracy 0.9321 AUC 0.5407\n","Epoch 7 Batch 950 Loss 0.0238 Accuracy 0.9321 AUC 0.5411\n","Epoch 7 Batch 960 Loss 0.0238 Accuracy 0.9319 AUC 0.5418\n","Epoch 7 Batch 970 Loss 0.0238 Accuracy 0.9320 AUC 0.5417\n","Epoch 7 Batch 980 Loss 0.0238 Accuracy 0.9321 AUC 0.5417\n","Epoch 7 Batch 990 Loss 0.0238 Accuracy 0.9321 AUC 0.5417\n","Epoch 7 Batch 1000 Loss 0.0238 Accuracy 0.9321 AUC 0.5415\n","Epoch 7 Batch 1010 Loss 0.0238 Accuracy 0.9319 AUC 0.5428\n","Epoch 7 Batch 1020 Loss 0.0238 Accuracy 0.9318 AUC 0.5430\n","Epoch 7 Batch 1030 Loss 0.0238 Accuracy 0.9319 AUC 0.5435\n","Epoch 7 Batch 1040 Loss 0.0238 Accuracy 0.9318 AUC 0.5437\n","Epoch 7 Batch 1050 Loss 0.0238 Accuracy 0.9318 AUC 0.5437\n","Epoch 7 Batch 1060 Loss 0.0238 Accuracy 0.9318 AUC 0.5434\n","Epoch 7 Batch 1070 Loss 0.0238 Accuracy 0.9318 AUC 0.5434\n","Epoch 7 Batch 1080 Loss 0.0238 Accuracy 0.9318 AUC 0.5436\n","Epoch 7 Batch 1090 Loss 0.0238 Accuracy 0.9319 AUC 0.5432\n","Epoch 7 Batch 1100 Loss 0.0238 Accuracy 0.9320 AUC 0.5434\n","Epoch 7 Batch 1110 Loss 0.0238 Accuracy 0.9319 AUC 0.5437\n","Epoch 7 Batch 1120 Loss 0.0237 Accuracy 0.9321 AUC 0.5439\n","Epoch 7 Batch 1130 Loss 0.0237 Accuracy 0.9323 AUC 0.5451\n","Epoch 7 Batch 1140 Loss 0.0237 Accuracy 0.9323 AUC 0.5450\n","Epoch 7 Batch 1150 Loss 0.0236 Accuracy 0.9325 AUC 0.5454\n","Epoch 7 Batch 1160 Loss 0.0237 Accuracy 0.9323 AUC 0.5450\n","Epoch 7 Batch 1170 Loss 0.0237 Accuracy 0.9322 AUC 0.5455\n","Epoch 7 Batch 1180 Loss 0.0237 Accuracy 0.9321 AUC 0.5454\n","Epoch 7 Batch 1190 Loss 0.0237 Accuracy 0.9322 AUC 0.5449\n","Epoch 7 Batch 1200 Loss 0.0238 Accuracy 0.9320 AUC 0.5451\n","Epoch 7 Batch 1210 Loss 0.0238 Accuracy 0.9320 AUC 0.5454\n","Epoch 7 Batch 1220 Loss 0.0238 Accuracy 0.9320 AUC 0.5456\n","Epoch 7 Batch 1230 Loss 0.0237 Accuracy 0.9321 AUC 0.5460\n","Epoch 7 Batch 1240 Loss 0.0237 Accuracy 0.9321 AUC 0.5457\n","Epoch 7 Batch 1250 Loss 0.0237 Accuracy 0.9322 AUC 0.5453\n","Epoch 7 Batch 1260 Loss 0.0237 Accuracy 0.9322 AUC 0.5461\n","Epoch 7 Batch 1270 Loss 0.0237 Accuracy 0.9324 AUC 0.5462\n","Epoch 7 Batch 1280 Loss 0.0237 Accuracy 0.9324 AUC 0.5454\n","Epoch 7 Batch 1290 Loss 0.0237 Accuracy 0.9324 AUC 0.5453\n","Epoch 7 Batch 1300 Loss 0.0237 Accuracy 0.9324 AUC 0.5452\n","Epoch 7 Batch 1310 Loss 0.0237 Accuracy 0.9324 AUC 0.5451\n","Epoch 7 Batch 1320 Loss 0.0237 Accuracy 0.9325 AUC 0.5448\n","Epoch 7 Batch 1330 Loss 0.0237 Accuracy 0.9324 AUC 0.5449\n","Epoch 7 Batch 1340 Loss 0.0237 Accuracy 0.9323 AUC 0.5454\n","Epoch 7 Batch 1350 Loss 0.0237 Accuracy 0.9322 AUC 0.5457\n","Epoch 7 Batch 1360 Loss 0.0237 Accuracy 0.9322 AUC 0.5456\n","Epoch 7 Batch 1370 Loss 0.0237 Accuracy 0.9323 AUC 0.5458\n","Epoch 7 Batch 1380 Loss 0.0237 Accuracy 0.9323 AUC 0.5461\n","Epoch 7 Batch 1390 Loss 0.0237 Accuracy 0.9324 AUC 0.5465\n","Epoch 7 Batch 1400 Loss 0.0236 Accuracy 0.9325 AUC 0.5468\n","Epoch 7 Batch 1410 Loss 0.0237 Accuracy 0.9324 AUC 0.5472\n","Epoch 7 Batch 1420 Loss 0.0236 Accuracy 0.9326 AUC 0.5467\n","Epoch 7 Batch 1430 Loss 0.0236 Accuracy 0.9325 AUC 0.5465\n","Epoch 7 Batch 1440 Loss 0.0237 Accuracy 0.9324 AUC 0.5462\n","Epoch 7 Batch 1450 Loss 0.0237 Accuracy 0.9324 AUC 0.5464\n","Epoch 7 Batch 1460 Loss 0.0236 Accuracy 0.9326 AUC 0.5468\n","Epoch 7 Batch 1470 Loss 0.0236 Accuracy 0.9326 AUC 0.5467\n","Epoch 7 Batch 1480 Loss 0.0236 Accuracy 0.9327 AUC 0.5466\n","Epoch 7 Batch 1490 Loss 0.0236 Accuracy 0.9325 AUC 0.5468\n","Epoch 7 Batch 1500 Loss 0.0236 Accuracy 0.9326 AUC 0.5465\n","Epoch 7 Batch 1510 Loss 0.0236 Accuracy 0.9326 AUC 0.5467\n","Epoch 7 Batch 1520 Loss 0.0236 Accuracy 0.9327 AUC 0.5466\n","Epoch 7 Batch 1530 Loss 0.0236 Accuracy 0.9326 AUC 0.5467\n","Epoch 7 Batch 1540 Loss 0.0236 Accuracy 0.9325 AUC 0.5469\n","Epoch 7 Batch 1550 Loss 0.0237 Accuracy 0.9324 AUC 0.5472\n","Epoch 7 Batch 1560 Loss 0.0237 Accuracy 0.9324 AUC 0.5471\n","Epoch 7 Batch 1570 Loss 0.0237 Accuracy 0.9324 AUC 0.5469\n","Epoch 7 Batch 1580 Loss 0.0237 Accuracy 0.9324 AUC 0.5469\n","Epoch 7 Batch 1590 Loss 0.0236 Accuracy 0.9325 AUC 0.5470\n","Epoch 7 Batch 1600 Loss 0.0236 Accuracy 0.9325 AUC 0.5471\n","Epoch 7 Batch 1610 Loss 0.0236 Accuracy 0.9325 AUC 0.5471\n","Epoch 7 Batch 1620 Loss 0.0236 Accuracy 0.9325 AUC 0.5472\n","Epoch 7 Batch 1630 Loss 0.0236 Accuracy 0.9324 AUC 0.5471\n","Epoch 7 Batch 1640 Loss 0.0236 Accuracy 0.9325 AUC 0.5475\n","Epoch 7 Batch 1650 Loss 0.0236 Accuracy 0.9326 AUC 0.5481\n","Epoch 7 Batch 1660 Loss 0.0236 Accuracy 0.9326 AUC 0.5483\n","Epoch 7 Batch 1670 Loss 0.0236 Accuracy 0.9326 AUC 0.5486\n","Epoch 7 Batch 1680 Loss 0.0236 Accuracy 0.9326 AUC 0.5486\n","Epoch 7 Batch 1690 Loss 0.0236 Accuracy 0.9325 AUC 0.5488\n","Epoch 7 Batch 1700 Loss 0.0236 Accuracy 0.9325 AUC 0.5492\n","Epoch 7 Batch 1710 Loss 0.0236 Accuracy 0.9324 AUC 0.5492\n","Epoch 7 Batch 1720 Loss 0.0236 Accuracy 0.9324 AUC 0.5495\n","Epoch 7 Batch 1730 Loss 0.0236 Accuracy 0.9324 AUC 0.5495\n","Epoch 7 Batch 1740 Loss 0.0236 Accuracy 0.9324 AUC 0.5497\n","Epoch 7 Batch 1750 Loss 0.0236 Accuracy 0.9324 AUC 0.5496\n","Epoch 7 Batch 1760 Loss 0.0236 Accuracy 0.9324 AUC 0.5498\n","Epoch 7 Batch 1770 Loss 0.0237 Accuracy 0.9323 AUC 0.5495\n","Epoch 7 Batch 1780 Loss 0.0236 Accuracy 0.9324 AUC 0.5494\n","Epoch 7 Batch 1790 Loss 0.0236 Accuracy 0.9325 AUC 0.5496\n","Epoch 7 Batch 1800 Loss 0.0236 Accuracy 0.9325 AUC 0.5496\n","Epoch 7 Batch 1810 Loss 0.0236 Accuracy 0.9325 AUC 0.5496\n","Epoch 7 Batch 1820 Loss 0.0236 Accuracy 0.9325 AUC 0.5498\n","Epoch 7 Batch 1830 Loss 0.0236 Accuracy 0.9324 AUC 0.5498\n","Epoch 7 Batch 1840 Loss 0.0236 Accuracy 0.9325 AUC 0.5497\n","Epoch 7 Batch 1850 Loss 0.0236 Accuracy 0.9325 AUC 0.5496\n","Epoch 7 Batch 1860 Loss 0.0236 Accuracy 0.9325 AUC 0.5495\n","Epoch 7 Batch 1870 Loss 0.0236 Accuracy 0.9325 AUC 0.5495\n","Epoch 7 Batch 1880 Loss 0.0236 Accuracy 0.9325 AUC 0.5496\n","Epoch 7 Batch 1890 Loss 0.0236 Accuracy 0.9324 AUC 0.5494\n","Epoch 7 Batch 1900 Loss 0.0236 Accuracy 0.9324 AUC 0.5496\n","Epoch 7 Batch 1910 Loss 0.0236 Accuracy 0.9324 AUC 0.5495\n","Epoch 7 Batch 1920 Loss 0.0236 Accuracy 0.9324 AUC 0.5492\n","Epoch 7 Batch 1930 Loss 0.0236 Accuracy 0.9324 AUC 0.5493\n","Epoch 7 Batch 1940 Loss 0.0236 Accuracy 0.9324 AUC 0.5496\n","Epoch 7 Batch 1950 Loss 0.0236 Accuracy 0.9325 AUC 0.5500\n","Epoch 7 Batch 1960 Loss 0.0236 Accuracy 0.9325 AUC 0.5499\n","Epoch 7 Batch 1970 Loss 0.0236 Accuracy 0.9325 AUC 0.5497\n","Epoch 7 Batch 1980 Loss 0.0236 Accuracy 0.9325 AUC 0.5498\n","Epoch 7 Batch 1990 Loss 0.0236 Accuracy 0.9325 AUC 0.5501\n","Epoch 7 Batch 2000 Loss 0.0236 Accuracy 0.9325 AUC 0.5502\n","Epoch 7 Batch 2010 Loss 0.0236 Accuracy 0.9325 AUC 0.5503\n","Epoch 7 Batch 2020 Loss 0.0236 Accuracy 0.9326 AUC 0.5502\n","Epoch 7 Batch 2030 Loss 0.0236 Accuracy 0.9325 AUC 0.5504\n","Epoch 7 Batch 2040 Loss 0.0236 Accuracy 0.9325 AUC 0.5504\n","Epoch 7 Batch 2050 Loss 0.0236 Accuracy 0.9324 AUC 0.5504\n","Epoch 7 Batch 2060 Loss 0.0236 Accuracy 0.9325 AUC 0.5501\n","Epoch 7 Batch 2070 Loss 0.0236 Accuracy 0.9325 AUC 0.5498\n","Epoch 7 Batch 2080 Loss 0.0236 Accuracy 0.9324 AUC 0.5498\n","Epoch 7 Batch 2090 Loss 0.0236 Accuracy 0.9325 AUC 0.5498\n","Epoch 7 Batch 2100 Loss 0.0236 Accuracy 0.9325 AUC 0.5499\n","Epoch 7 Loss 0.0236 Accuracy 0.9325\n","Time taken for 1 epoch: 719.833890914917 secs\n","\n","Epoch 8 Batch 0 Loss 0.0183 Accuracy 0.9531 AUC 0.7049\n","Epoch 8 Batch 10 Loss 0.0237 Accuracy 0.9332 AUC 0.5027\n","Epoch 8 Batch 20 Loss 0.0253 Accuracy 0.9256 AUC 0.5625\n","Epoch 8 Batch 30 Loss 0.0238 Accuracy 0.9325 AUC 0.5295\n","Epoch 8 Batch 40 Loss 0.0243 Accuracy 0.9303 AUC 0.5237\n","Epoch 8 Batch 50 Loss 0.0240 Accuracy 0.9314 AUC 0.5318\n","Epoch 8 Batch 60 Loss 0.0245 Accuracy 0.9293 AUC 0.5433\n","Epoch 8 Batch 70 Loss 0.0244 Accuracy 0.9298 AUC 0.5406\n","Epoch 8 Batch 80 Loss 0.0246 Accuracy 0.9290 AUC 0.5340\n","Epoch 8 Batch 90 Loss 0.0244 Accuracy 0.9296 AUC 0.5365\n","Epoch 8 Batch 100 Loss 0.0244 Accuracy 0.9299 AUC 0.5325\n","Epoch 8 Batch 110 Loss 0.0245 Accuracy 0.9293 AUC 0.5309\n","Epoch 8 Batch 120 Loss 0.0243 Accuracy 0.9301 AUC 0.5354\n","Epoch 8 Batch 130 Loss 0.0243 Accuracy 0.9302 AUC 0.5341\n","Epoch 8 Batch 140 Loss 0.0242 Accuracy 0.9305 AUC 0.5311\n","Epoch 8 Batch 150 Loss 0.0241 Accuracy 0.9308 AUC 0.5302\n","Epoch 8 Batch 160 Loss 0.0242 Accuracy 0.9303 AUC 0.5315\n","Epoch 8 Batch 170 Loss 0.0243 Accuracy 0.9301 AUC 0.5310\n","Epoch 8 Batch 180 Loss 0.0243 Accuracy 0.9302 AUC 0.5324\n","Epoch 8 Batch 190 Loss 0.0242 Accuracy 0.9305 AUC 0.5299\n","Epoch 8 Batch 200 Loss 0.0243 Accuracy 0.9301 AUC 0.5327\n","Epoch 8 Batch 210 Loss 0.0241 Accuracy 0.9310 AUC 0.5317\n","Epoch 8 Batch 220 Loss 0.0240 Accuracy 0.9314 AUC 0.5302\n","Epoch 8 Batch 230 Loss 0.0237 Accuracy 0.9323 AUC 0.5354\n","Epoch 8 Batch 240 Loss 0.0236 Accuracy 0.9326 AUC 0.5365\n","Epoch 8 Batch 250 Loss 0.0237 Accuracy 0.9323 AUC 0.5331\n","Epoch 8 Batch 260 Loss 0.0237 Accuracy 0.9324 AUC 0.5326\n","Epoch 8 Batch 270 Loss 0.0237 Accuracy 0.9325 AUC 0.5292\n","Epoch 8 Batch 280 Loss 0.0235 Accuracy 0.9332 AUC 0.5314\n","Epoch 8 Batch 290 Loss 0.0235 Accuracy 0.9332 AUC 0.5315\n","Epoch 8 Batch 300 Loss 0.0234 Accuracy 0.9335 AUC 0.5326\n","Epoch 8 Batch 310 Loss 0.0236 Accuracy 0.9332 AUC 0.5287\n","Epoch 8 Batch 320 Loss 0.0236 Accuracy 0.9330 AUC 0.5293\n","Epoch 8 Batch 330 Loss 0.0236 Accuracy 0.9330 AUC 0.5301\n","Epoch 8 Batch 340 Loss 0.0236 Accuracy 0.9331 AUC 0.5307\n","Epoch 8 Batch 350 Loss 0.0236 Accuracy 0.9331 AUC 0.5298\n","Epoch 8 Batch 360 Loss 0.0236 Accuracy 0.9329 AUC 0.5301\n","Epoch 8 Batch 370 Loss 0.0237 Accuracy 0.9325 AUC 0.5310\n","Epoch 8 Batch 380 Loss 0.0236 Accuracy 0.9328 AUC 0.5311\n","Epoch 8 Batch 390 Loss 0.0237 Accuracy 0.9326 AUC 0.5304\n","Epoch 8 Batch 400 Loss 0.0237 Accuracy 0.9326 AUC 0.5299\n","Epoch 8 Batch 410 Loss 0.0236 Accuracy 0.9327 AUC 0.5310\n","Epoch 8 Batch 420 Loss 0.0236 Accuracy 0.9329 AUC 0.5329\n","Epoch 8 Batch 430 Loss 0.0235 Accuracy 0.9331 AUC 0.5368\n","Epoch 8 Batch 440 Loss 0.0235 Accuracy 0.9332 AUC 0.5391\n","Epoch 8 Batch 450 Loss 0.0235 Accuracy 0.9330 AUC 0.5393\n","Epoch 8 Batch 460 Loss 0.0236 Accuracy 0.9330 AUC 0.5392\n","Epoch 8 Batch 470 Loss 0.0236 Accuracy 0.9328 AUC 0.5383\n","Epoch 8 Batch 480 Loss 0.0236 Accuracy 0.9328 AUC 0.5390\n","Epoch 8 Batch 490 Loss 0.0235 Accuracy 0.9330 AUC 0.5383\n","Epoch 8 Batch 500 Loss 0.0236 Accuracy 0.9329 AUC 0.5384\n","Epoch 8 Batch 510 Loss 0.0235 Accuracy 0.9330 AUC 0.5389\n","Epoch 8 Batch 520 Loss 0.0236 Accuracy 0.9326 AUC 0.5382\n","Epoch 8 Batch 530 Loss 0.0236 Accuracy 0.9327 AUC 0.5379\n","Epoch 8 Batch 540 Loss 0.0236 Accuracy 0.9327 AUC 0.5360\n","Epoch 8 Batch 550 Loss 0.0236 Accuracy 0.9328 AUC 0.5356\n","Epoch 8 Batch 560 Loss 0.0236 Accuracy 0.9327 AUC 0.5344\n","Epoch 8 Batch 570 Loss 0.0236 Accuracy 0.9327 AUC 0.5354\n","Epoch 8 Batch 580 Loss 0.0236 Accuracy 0.9328 AUC 0.5354\n","Epoch 8 Batch 590 Loss 0.0237 Accuracy 0.9326 AUC 0.5354\n","Epoch 8 Batch 600 Loss 0.0237 Accuracy 0.9325 AUC 0.5348\n","Epoch 8 Batch 610 Loss 0.0237 Accuracy 0.9325 AUC 0.5348\n","Epoch 8 Batch 620 Loss 0.0237 Accuracy 0.9325 AUC 0.5352\n","Epoch 8 Batch 630 Loss 0.0237 Accuracy 0.9326 AUC 0.5347\n","Epoch 8 Batch 640 Loss 0.0237 Accuracy 0.9323 AUC 0.5352\n","Epoch 8 Batch 650 Loss 0.0237 Accuracy 0.9325 AUC 0.5351\n","Epoch 8 Batch 660 Loss 0.0237 Accuracy 0.9325 AUC 0.5348\n","Epoch 8 Batch 670 Loss 0.0237 Accuracy 0.9323 AUC 0.5352\n","Epoch 8 Batch 680 Loss 0.0238 Accuracy 0.9320 AUC 0.5349\n","Epoch 8 Batch 690 Loss 0.0239 Accuracy 0.9317 AUC 0.5361\n","Epoch 8 Batch 700 Loss 0.0239 Accuracy 0.9317 AUC 0.5358\n","Epoch 8 Batch 710 Loss 0.0238 Accuracy 0.9318 AUC 0.5365\n","Epoch 8 Batch 720 Loss 0.0238 Accuracy 0.9319 AUC 0.5371\n","Epoch 8 Batch 730 Loss 0.0237 Accuracy 0.9322 AUC 0.5382\n","Epoch 8 Batch 740 Loss 0.0238 Accuracy 0.9320 AUC 0.5384\n","Epoch 8 Batch 750 Loss 0.0238 Accuracy 0.9318 AUC 0.5387\n","Epoch 8 Batch 760 Loss 0.0239 Accuracy 0.9316 AUC 0.5383\n","Epoch 8 Batch 770 Loss 0.0239 Accuracy 0.9316 AUC 0.5380\n","Epoch 8 Batch 780 Loss 0.0239 Accuracy 0.9316 AUC 0.5384\n","Epoch 8 Batch 790 Loss 0.0238 Accuracy 0.9318 AUC 0.5392\n","Epoch 8 Batch 800 Loss 0.0238 Accuracy 0.9319 AUC 0.5404\n","Epoch 8 Batch 810 Loss 0.0238 Accuracy 0.9319 AUC 0.5408\n","Epoch 8 Batch 820 Loss 0.0238 Accuracy 0.9318 AUC 0.5411\n","Epoch 8 Batch 830 Loss 0.0238 Accuracy 0.9320 AUC 0.5406\n","Epoch 8 Batch 840 Loss 0.0238 Accuracy 0.9320 AUC 0.5417\n","Epoch 8 Batch 850 Loss 0.0238 Accuracy 0.9319 AUC 0.5418\n","Epoch 8 Batch 860 Loss 0.0238 Accuracy 0.9319 AUC 0.5409\n","Epoch 8 Batch 870 Loss 0.0238 Accuracy 0.9320 AUC 0.5408\n","Epoch 8 Batch 880 Loss 0.0238 Accuracy 0.9318 AUC 0.5409\n","Epoch 8 Batch 890 Loss 0.0238 Accuracy 0.9318 AUC 0.5401\n","Epoch 8 Batch 900 Loss 0.0238 Accuracy 0.9320 AUC 0.5402\n","Epoch 8 Batch 910 Loss 0.0238 Accuracy 0.9320 AUC 0.5402\n","Epoch 8 Batch 920 Loss 0.0238 Accuracy 0.9321 AUC 0.5405\n","Epoch 8 Batch 930 Loss 0.0238 Accuracy 0.9321 AUC 0.5407\n","Epoch 8 Batch 940 Loss 0.0238 Accuracy 0.9321 AUC 0.5402\n","Epoch 8 Batch 950 Loss 0.0238 Accuracy 0.9321 AUC 0.5403\n","Epoch 8 Batch 960 Loss 0.0238 Accuracy 0.9319 AUC 0.5409\n","Epoch 8 Batch 970 Loss 0.0238 Accuracy 0.9320 AUC 0.5404\n","Epoch 8 Batch 980 Loss 0.0238 Accuracy 0.9321 AUC 0.5407\n","Epoch 8 Batch 990 Loss 0.0238 Accuracy 0.9321 AUC 0.5413\n","Epoch 8 Batch 1000 Loss 0.0238 Accuracy 0.9321 AUC 0.5412\n","Epoch 8 Batch 1010 Loss 0.0238 Accuracy 0.9319 AUC 0.5419\n","Epoch 8 Batch 1020 Loss 0.0238 Accuracy 0.9318 AUC 0.5420\n","Epoch 8 Batch 1030 Loss 0.0238 Accuracy 0.9319 AUC 0.5426\n","Epoch 8 Batch 1040 Loss 0.0238 Accuracy 0.9318 AUC 0.5428\n","Epoch 8 Batch 1050 Loss 0.0238 Accuracy 0.9318 AUC 0.5432\n","Epoch 8 Batch 1060 Loss 0.0238 Accuracy 0.9318 AUC 0.5427\n","Epoch 8 Batch 1070 Loss 0.0238 Accuracy 0.9318 AUC 0.5427\n","Epoch 8 Batch 1080 Loss 0.0238 Accuracy 0.9318 AUC 0.5430\n","Epoch 8 Batch 1090 Loss 0.0238 Accuracy 0.9319 AUC 0.5425\n","Epoch 8 Batch 1100 Loss 0.0238 Accuracy 0.9320 AUC 0.5427\n","Epoch 8 Batch 1110 Loss 0.0238 Accuracy 0.9319 AUC 0.5429\n","Epoch 8 Batch 1120 Loss 0.0237 Accuracy 0.9321 AUC 0.5433\n","Epoch 8 Batch 1130 Loss 0.0237 Accuracy 0.9323 AUC 0.5443\n","Epoch 8 Batch 1140 Loss 0.0237 Accuracy 0.9323 AUC 0.5443\n","Epoch 8 Batch 1150 Loss 0.0236 Accuracy 0.9325 AUC 0.5447\n","Epoch 8 Batch 1160 Loss 0.0237 Accuracy 0.9323 AUC 0.5445\n","Epoch 8 Batch 1170 Loss 0.0237 Accuracy 0.9322 AUC 0.5452\n","Epoch 8 Batch 1180 Loss 0.0237 Accuracy 0.9321 AUC 0.5453\n","Epoch 8 Batch 1190 Loss 0.0237 Accuracy 0.9322 AUC 0.5448\n","Epoch 8 Batch 1200 Loss 0.0237 Accuracy 0.9320 AUC 0.5447\n","Epoch 8 Batch 1210 Loss 0.0238 Accuracy 0.9320 AUC 0.5446\n","Epoch 8 Batch 1220 Loss 0.0238 Accuracy 0.9320 AUC 0.5442\n","Epoch 8 Batch 1230 Loss 0.0237 Accuracy 0.9321 AUC 0.5443\n","Epoch 8 Batch 1240 Loss 0.0237 Accuracy 0.9321 AUC 0.5438\n","Epoch 8 Batch 1250 Loss 0.0237 Accuracy 0.9322 AUC 0.5437\n","Epoch 8 Batch 1260 Loss 0.0237 Accuracy 0.9322 AUC 0.5444\n","Epoch 8 Batch 1270 Loss 0.0237 Accuracy 0.9324 AUC 0.5445\n","Epoch 8 Batch 1280 Loss 0.0237 Accuracy 0.9324 AUC 0.5439\n","Epoch 8 Batch 1290 Loss 0.0237 Accuracy 0.9324 AUC 0.5440\n","Epoch 8 Batch 1300 Loss 0.0237 Accuracy 0.9324 AUC 0.5443\n","Epoch 8 Batch 1310 Loss 0.0237 Accuracy 0.9324 AUC 0.5440\n","Epoch 8 Batch 1320 Loss 0.0237 Accuracy 0.9325 AUC 0.5438\n","Epoch 8 Batch 1330 Loss 0.0237 Accuracy 0.9324 AUC 0.5442\n","Epoch 8 Batch 1340 Loss 0.0237 Accuracy 0.9323 AUC 0.5447\n","Epoch 8 Batch 1350 Loss 0.0237 Accuracy 0.9322 AUC 0.5447\n","Epoch 8 Batch 1360 Loss 0.0237 Accuracy 0.9322 AUC 0.5444\n","Epoch 8 Batch 1370 Loss 0.0237 Accuracy 0.9323 AUC 0.5445\n","Epoch 8 Batch 1380 Loss 0.0237 Accuracy 0.9323 AUC 0.5448\n","Epoch 8 Batch 1390 Loss 0.0237 Accuracy 0.9324 AUC 0.5450\n","Epoch 8 Batch 1400 Loss 0.0236 Accuracy 0.9325 AUC 0.5452\n","Epoch 8 Batch 1410 Loss 0.0237 Accuracy 0.9324 AUC 0.5457\n","Epoch 8 Batch 1420 Loss 0.0236 Accuracy 0.9326 AUC 0.5453\n","Epoch 8 Batch 1430 Loss 0.0236 Accuracy 0.9325 AUC 0.5451\n","Epoch 8 Batch 1440 Loss 0.0237 Accuracy 0.9324 AUC 0.5449\n","Epoch 8 Batch 1450 Loss 0.0237 Accuracy 0.9324 AUC 0.5449\n","Epoch 8 Batch 1460 Loss 0.0236 Accuracy 0.9326 AUC 0.5453\n","Epoch 8 Batch 1470 Loss 0.0236 Accuracy 0.9326 AUC 0.5451\n","Epoch 8 Batch 1480 Loss 0.0236 Accuracy 0.9327 AUC 0.5453\n","Epoch 8 Batch 1490 Loss 0.0236 Accuracy 0.9325 AUC 0.5457\n","Epoch 8 Batch 1500 Loss 0.0236 Accuracy 0.9326 AUC 0.5453\n","Epoch 8 Batch 1510 Loss 0.0236 Accuracy 0.9326 AUC 0.5451\n","Epoch 8 Batch 1520 Loss 0.0236 Accuracy 0.9327 AUC 0.5449\n","Epoch 8 Batch 1530 Loss 0.0236 Accuracy 0.9326 AUC 0.5449\n","Epoch 8 Batch 1540 Loss 0.0236 Accuracy 0.9325 AUC 0.5452\n","Epoch 8 Batch 1550 Loss 0.0237 Accuracy 0.9324 AUC 0.5455\n","Epoch 8 Batch 1560 Loss 0.0236 Accuracy 0.9324 AUC 0.5454\n","Epoch 8 Batch 1570 Loss 0.0237 Accuracy 0.9324 AUC 0.5455\n","Epoch 8 Batch 1580 Loss 0.0236 Accuracy 0.9324 AUC 0.5457\n","Epoch 8 Batch 1590 Loss 0.0236 Accuracy 0.9325 AUC 0.5459\n","Epoch 8 Batch 1600 Loss 0.0236 Accuracy 0.9325 AUC 0.5460\n","Epoch 8 Batch 1610 Loss 0.0236 Accuracy 0.9325 AUC 0.5460\n","Epoch 8 Batch 1620 Loss 0.0236 Accuracy 0.9325 AUC 0.5463\n","Epoch 8 Batch 1630 Loss 0.0236 Accuracy 0.9324 AUC 0.5464\n","Epoch 8 Batch 1640 Loss 0.0236 Accuracy 0.9325 AUC 0.5469\n","Epoch 8 Batch 1650 Loss 0.0236 Accuracy 0.9326 AUC 0.5477\n","Epoch 8 Batch 1660 Loss 0.0236 Accuracy 0.9326 AUC 0.5477\n","Epoch 8 Batch 1670 Loss 0.0236 Accuracy 0.9326 AUC 0.5482\n","Epoch 8 Batch 1680 Loss 0.0236 Accuracy 0.9326 AUC 0.5483\n","Epoch 8 Batch 1690 Loss 0.0236 Accuracy 0.9325 AUC 0.5484\n","Epoch 8 Batch 1700 Loss 0.0236 Accuracy 0.9325 AUC 0.5488\n","Epoch 8 Batch 1710 Loss 0.0236 Accuracy 0.9324 AUC 0.5489\n","Epoch 8 Batch 1720 Loss 0.0236 Accuracy 0.9324 AUC 0.5492\n","Epoch 8 Batch 1730 Loss 0.0236 Accuracy 0.9324 AUC 0.5493\n","Epoch 8 Batch 1740 Loss 0.0236 Accuracy 0.9324 AUC 0.5496\n","Epoch 8 Batch 1750 Loss 0.0236 Accuracy 0.9324 AUC 0.5495\n","Epoch 8 Batch 1760 Loss 0.0236 Accuracy 0.9324 AUC 0.5496\n","Epoch 8 Batch 1770 Loss 0.0236 Accuracy 0.9323 AUC 0.5496\n","Epoch 8 Batch 1780 Loss 0.0236 Accuracy 0.9324 AUC 0.5494\n","Epoch 8 Batch 1790 Loss 0.0236 Accuracy 0.9325 AUC 0.5495\n","Epoch 8 Batch 1800 Loss 0.0236 Accuracy 0.9325 AUC 0.5495\n","Epoch 8 Batch 1810 Loss 0.0236 Accuracy 0.9325 AUC 0.5494\n","Epoch 8 Batch 1820 Loss 0.0236 Accuracy 0.9325 AUC 0.5497\n","Epoch 8 Batch 1830 Loss 0.0236 Accuracy 0.9324 AUC 0.5500\n","Epoch 8 Batch 1840 Loss 0.0236 Accuracy 0.9325 AUC 0.5499\n","Epoch 8 Batch 1850 Loss 0.0236 Accuracy 0.9325 AUC 0.5500\n","Epoch 8 Batch 1860 Loss 0.0236 Accuracy 0.9325 AUC 0.5501\n","Epoch 8 Batch 1870 Loss 0.0236 Accuracy 0.9325 AUC 0.5502\n","Epoch 8 Batch 1880 Loss 0.0236 Accuracy 0.9325 AUC 0.5504\n","Epoch 8 Batch 1890 Loss 0.0236 Accuracy 0.9324 AUC 0.5501\n","Epoch 8 Batch 1900 Loss 0.0236 Accuracy 0.9324 AUC 0.5503\n","Epoch 8 Batch 1910 Loss 0.0236 Accuracy 0.9324 AUC 0.5499\n","Epoch 8 Batch 1920 Loss 0.0236 Accuracy 0.9324 AUC 0.5495\n","Epoch 8 Batch 1930 Loss 0.0236 Accuracy 0.9324 AUC 0.5497\n","Epoch 8 Batch 1940 Loss 0.0236 Accuracy 0.9324 AUC 0.5498\n","Epoch 8 Batch 1950 Loss 0.0236 Accuracy 0.9325 AUC 0.5502\n","Epoch 8 Batch 1960 Loss 0.0236 Accuracy 0.9325 AUC 0.5501\n","Epoch 8 Batch 1970 Loss 0.0236 Accuracy 0.9325 AUC 0.5501\n","Epoch 8 Batch 1980 Loss 0.0236 Accuracy 0.9325 AUC 0.5503\n","Epoch 8 Batch 1990 Loss 0.0236 Accuracy 0.9325 AUC 0.5506\n","Epoch 8 Batch 2000 Loss 0.0236 Accuracy 0.9325 AUC 0.5506\n","Epoch 8 Batch 2010 Loss 0.0236 Accuracy 0.9325 AUC 0.5505\n","Epoch 8 Batch 2020 Loss 0.0236 Accuracy 0.9326 AUC 0.5505\n","Epoch 8 Batch 2030 Loss 0.0236 Accuracy 0.9325 AUC 0.5506\n","Epoch 8 Batch 2040 Loss 0.0236 Accuracy 0.9325 AUC 0.5508\n","Epoch 8 Batch 2050 Loss 0.0236 Accuracy 0.9324 AUC 0.5508\n","Epoch 8 Batch 2060 Loss 0.0236 Accuracy 0.9325 AUC 0.5505\n","Epoch 8 Batch 2070 Loss 0.0236 Accuracy 0.9325 AUC 0.5503\n","Epoch 8 Batch 2080 Loss 0.0236 Accuracy 0.9324 AUC 0.5502\n","Epoch 8 Batch 2090 Loss 0.0236 Accuracy 0.9325 AUC 0.5502\n","Epoch 8 Batch 2100 Loss 0.0236 Accuracy 0.9325 AUC 0.5503\n","Epoch 8 Loss 0.0236 Accuracy 0.9325\n","Time taken for 1 epoch: 724.9727258682251 secs\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JZFgti_QJwVW","colab_type":"text"},"source":["# Evaluate"]},{"cell_type":"code","metadata":{"id":"Xk2WQg8pVDob","colab_type":"code","colab":{}},"source":["test_predictions, _ = sample_transformer(test_behavior, test_stay_time, True, len(test_label))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUSBBJuxVDrK","colab_type":"code","outputId":"791a2992-c6a8-4a04-fa71-fe02d2964ec6","executionInfo":{"status":"ok","timestamp":1590101228530,"user_tz":-480,"elapsed":5841969,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_AUC.reset_states()\n","train_AUC.update_state(test_label,test_predictions)\n","auc = train_AUC.result().numpy()\n","print(\"AUC result:\", auc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["AUC result: 0.5616562\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ih2AB4mWQqA2","colab_type":"code","outputId":"b71edde0-ba8d-439a-ff9a-426d143266c5","executionInfo":{"status":"ok","timestamp":1590101228530,"user_tz":-480,"elapsed":5841965,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_accuracy.update_state(test_label, test_predictions)\n","accuracy = train_accuracy.result().numpy()\n","print(\"Accuracy:\", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.93245053\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPNCYry6jDGw","colab_type":"code","outputId":"d60c7fce-aea6-48d0-b0f0-282ac46f2ae6","executionInfo":{"status":"ok","timestamp":1590108939167,"user_tz":-480,"elapsed":878,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["fpr, tpr, threshold = roc_curve(test_label, test_predictions)\n","ks = (tpr-fpr)\n","max_ = np.argmax(ks)\n","print(\"KS:\", ks)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.10732105194471692"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"bOmuFKwKn0Ct","colab_type":"code","outputId":"032ff2ff-303f-48f2-8be2-a679d2c527e6","executionInfo":{"status":"ok","timestamp":1590108998480,"user_tz":-480,"elapsed":772,"user":{"displayName":"Hanyu Wu","photoUrl":"","userId":"05588030028148674891"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"9KGPXJRH4Cnr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}